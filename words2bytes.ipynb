{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('transformer': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d0c581f552870128e643fa5d90873e1c0b3206e5e070517b42e73fec9b0f9803"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# imports\n",
    "import enum\n",
    "import io\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtext import datasets, vocab\n",
    "from torchtext.data import Field, BPTTIterator\n",
    "from torchtext.utils import download_from_url, extract_archive\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils \n",
    "def extract_config(config, *argv):\n",
    "    assert len(argv) > 0, \"No keys to extract\"\n",
    "    config_values = []\n",
    "    for key in argv:\n",
    "        assert key in config, f\"Key '{key}' not in config\"\n",
    "        config_values.append(config[key])\n",
    "    \n",
    "    return tuple(config_values) if len(argv) > 1 else config_values[0]\n",
    "\n",
    "def validate_config(config):\n",
    "    embedding_dimension, n_attention_heads = extract_config(config, \"embedding_dimension\", \"n_attention_heads\")\n",
    "    \n",
    "    # embedding dimension must be divisible by n_attention_heads\n",
    "    assert embedding_dimension %  n_attention_heads == 0, f\"Embedding dimension ({embedding_dimension}) must be divisible by n_attention_heads ({n_attention_heads})\"\n",
    "\n",
    "def emb_to_string(emb, vocab):\n",
    "    embeddings = vocab.itos\n",
    "    words = [ embeddings[item] for item in emb ]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch functions\n",
    "def batchify(data, bsz, device):\n",
    "    # Divide the dataset into bsz parts.\n",
    "    nbatch = data.size(0) // bsz\n",
    "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
    "    data = data.narrow(0, 0, nbatch * bsz)\n",
    "    # Evenly divide the data across the bsz batches.\n",
    "    data = data.view(bsz, -1).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "\n",
    "def get_batch(max_seq_len, source, i):\n",
    "    seq_len = min(max_seq_len, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target\n",
    "\n",
    "# load training data\n",
    "def load_data(config):\n",
    "    print(\"[Start Load Data]\")\n",
    "    ts = time.time()\n",
    "\n",
    "    # get dataset\n",
    "    dataset = extract_config(config, \"dataset\")\n",
    "    dataset = getattr(datasets, dataset.name) \n",
    "    tokenizer = get_tokenizer('basic_english')\n",
    "    field_processor = Field(tokenize=tokenizer)\n",
    "    print(f\"Fetched Data ({time.time() - ts:3f}s)\")\n",
    "\n",
    "    # split dataset\n",
    "    train_dataset, val_dataset, test_dataset = dataset.splits(text_field=field_processor)\n",
    "    print(f\"Split Data ({time.time() - ts:3f}s)\")\n",
    "\n",
    "    # get vocabulary\n",
    "    field_processor.build_vocab(train_dataset, val_dataset, test_dataset, min_freq=1)\n",
    "    vocab = field_processor.vocab\n",
    "    print(f\"Build Vocab ({time.time() - ts:3f}s)\")\n",
    "\n",
    "\n",
    "    def data_process(tt_dataset_split):\n",
    "        raw_text_iter = tt_dataset_split[0].text\n",
    "        data = [torch.tensor([vocab[token] for token in tokenizer(item)],\n",
    "                            dtype=torch.long) for item in raw_text_iter]\n",
    "        return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "    train_data = data_process(train_dataset)\n",
    "    val_data = data_process(val_dataset)\n",
    "    test_data = data_process(test_dataset)\n",
    "\n",
    "    print(f\"[End Load Data] ({time.time() - ts:3f}s)\")\n",
    "    return train_data, val_data, test_data, vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch lightning stuff\n",
    "def load_data_pl(config): \n",
    "    # get dataset\n",
    "    dataset = extract_config(config, \"dataset\")\n",
    "    dataset = getattr(datasets, dataset.name) \n",
    "    tokenizer = get_tokenizer('basic_english')\n",
    "    field_processor = Field(tokenize=tokenizer)\n",
    "\n",
    "    # split dataset\n",
    "    train_dataset, val_dataset, test_dataset = dataset.splits(text_field=field_processor)\n",
    "    \n",
    "    # get vocabulary\n",
    "    field_processor.build_vocab(train_dataset, val_dataset, test_dataset, min_freq=1)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, field_processor\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate/visualize artifacts\n",
    "def initalize_artifacts(config, train_data_batches, val_data_batches):\n",
    "        n_epochs, max_seq_len = extract_config(config, \"n_epochs\", \"max_seq_len\")\n",
    "        training_cel = torch.ones(n_epochs, math.ceil(len(train_data_batches) / max_seq_len)) * float(\"inf\")\n",
    "        validation_cel = torch.ones(n_epochs, math.ceil(len(val_data_batches) / max_seq_len)) * float(\"inf\")\n",
    "        artifacts = {\n",
    "            \"training\": {\n",
    "                \"CrossEntropyLoss\": training_cel\n",
    "            },\n",
    "            \"validation\": {\n",
    "                \"CrossEntropyLoss\": validation_cel\n",
    "            }\n",
    "        }\n",
    "        return artifacts\n",
    "\n",
    "def update_artifact_loss(artifacts, training_stage, metric, epoch, batch, value):\n",
    "    try:\n",
    "        artifacts[training_stage][metric][epoch - 1][batch] = value\n",
    "    except Exception as e:\n",
    "        print(\"exception:\", e)\n",
    "        print(\"epoch\", epoch)\n",
    "        print(\"batch\", batch)\n",
    "        print(artifacts)\n",
    "\n",
    "def visualize_artifacts(artifacts):\n",
    "    flat_loss = artifacts['training']['CrossEntropyLoss'].reshape(-1)\n",
    "    count = flat_loss.size(0)\n",
    "    batch_number = np.arange(0, flat_loss.size(0))\n",
    "    plt.plot(batch_number, flat_loss)\n",
    "    plt.legend(\"CrossEntropyLoss\")\n",
    "    None\n",
    "\n",
    "# artifacts = initalize_artifacts(config, train_data_batches, val_data_batches)\n",
    "# update_artifact_loss(artifacts, 'training', 'CrossEntropyLoss', 0, 1, 0.5)\n",
    "# update_artifact_loss(artifacts, 'training', 'CrossEntropyLoss', 0, 2, 3)\n",
    "# # artifacts['training']['CrossEntropyLoss'].reshape(-1)\n",
    "# visualize_artifacts(artifacts)\n",
    "# # visualize_artifacts(artifacts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder only transformer implementation\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoderLayer, TransformerDecoder, LayerNorm\n",
    "from torch import Tensor\n",
    "from typing import Optional, Any\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# Decoder Only implmentation without memory for encoder\n",
    "# Adapted from pytorch implmentation @ https://pytorch.org/docs/stable/_modules/torch/nn/modules/transformer.html#TransformerDecoderLayer\n",
    "class CustomTransformerDecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, activation=\"relu\"):\n",
    "        super(CustomTransformerDecoderLayer, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
    "        # Implementation of Feedforward model\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "        self.norm1 = LayerNorm(d_model)\n",
    "        self.norm2 = LayerNorm(d_model) # skip\n",
    "        self.norm3 = LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout) # skip\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "        self.activation = _get_activation_fn(activation)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        if 'activation' not in state:\n",
    "            state['activation'] = F.relu\n",
    "        super(CustomTransformerDecoderLayer, self).__setstate__(state)\n",
    "\n",
    "    def forward(self, tgt: Tensor, memory: Tensor, tgt_mask: Optional[Tensor] = None, memory_mask: Optional[Tensor] = None,\n",
    "                tgt_key_padding_mask: Optional[Tensor] = None, memory_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
    "\n",
    "        tgt2 = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask,\n",
    "                              key_padding_mask=tgt_key_padding_mask)[0]\n",
    "        tgt = tgt + self.dropout1(tgt2)\n",
    "        tgt = self.norm1(tgt)\n",
    "        # tgt2 = self.multihead_attn(tgt, memory, memory, attn_mask=memory_mask,\n",
    "        #                            key_padding_mask=memory_key_padding_mask)[0]\n",
    "        # tgt = tgt + self.dropout2(tgt2)\n",
    "        # tgt = self.norm2(tgt)\n",
    "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
    "        tgt = tgt + self.dropout3(tgt2)\n",
    "        tgt = self.norm3(tgt)\n",
    "        return tgt\n",
    "\n",
    "\n",
    "\n",
    "def _get_clones(module, N):\n",
    "    return ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "\n",
    "def _get_activation_fn(activation):\n",
    "    if activation == \"relu\":\n",
    "        return F.relu\n",
    "    elif activation == \"gelu\":\n",
    "        return F.gelu\n",
    "\n",
    "    raise RuntimeError(\"activation should be relu/gelu, not {}\".format(activation))\n",
    "\n",
    "# decoder only implmentation\n",
    "# pytorch implmentation for torch ligthning\n",
    "# class Transformer(pl.LightningModule):\n",
    "class DecoderOnlyTransformer(nn.Module):\n",
    "    def __init__(self, ntokens, d_model=512, nhead=8, num_encoder_layers=6,\n",
    "                 num_decoder_layers=6, dim_feedforward=2048, dropout=0.1,\n",
    "                 activation=\"relu\", custom_encoder=None, custom_decoder=None):\n",
    "        super(DecoderOnlyTransformer, self).__init__()\n",
    "        # model vars\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "\n",
    "        # decoder setup \n",
    "        decoder_layer = CustomTransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout, activation)\n",
    "        decoder_norm = LayerNorm(d_model)\n",
    "        self.decoder = TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm)\n",
    "\n",
    "        # embedding setup\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        self.to_embedding = nn.Embedding(ntokens, d_model)\n",
    "\n",
    "        # output setup\n",
    "        self.linear = nn.Linear(d_model, ntokens)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "\n",
    "    def forward(self, tgt, tgt_mask=None, memory_mask=None,\n",
    "                tgt_key_padding_mask=None, memory_key_padding_mask=None):\n",
    "   \n",
    "        # convert input/targets to embeddings\n",
    "        tgt = self.to_embedding(tgt) * math.sqrt(self.d_model)\n",
    "\n",
    "        # add positional encodings\n",
    "        tgt = self.pos_encoder(tgt)\n",
    "\n",
    "        # pytorch checks\n",
    "        # https://pytorch.org/docs/master/generated/torch.nn.Transformer.html#torch.nn.Transformer.forward\n",
    "        if  tgt.size(2) != self.d_model:\n",
    "            raise RuntimeError(\"the feature number of tgt must be equal to d_model\")\n",
    "        \n",
    "        # decoder pass\n",
    "        output = self.decoder(tgt, memory=None, tgt_mask=tgt_mask,\n",
    "                              tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "                              memory_key_padding_mask=memory_key_padding_mask)\n",
    "        # return after linear layer\n",
    "        return self.linear(output)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Start Load Data]\n",
      "Fetched Data (0.000023s)\n",
      "Split Data (0.735732s)\n",
      "Build Vocab (0.920997s)\n",
      "[End Load Data] (14.485447s)\n"
     ]
    }
   ],
   "source": [
    "# constants/enums\n",
    "class Dataset(enum.Enum):\n",
    "    PennTreebank = 0,\n",
    "    WikiText2 = 1,\n",
    "    WikiText103 = 2\n",
    "\n",
    "class LanguageTask(enum.Enum):\n",
    "    CausalLanuageModeling = 0,\n",
    "    MaskedLanuageModeling = 1\n",
    "\n",
    "class Segmentation(enum.Enum):\n",
    "    Word = 0,\n",
    "    Subword = 1\n",
    "    Character = 2\n",
    "    BPE = 3\n",
    "    BBPE = 4\n",
    "    BYTE = 5\n",
    "\n",
    "# configure model\n",
    "config = {\n",
    "    \"embedding_dimension\": 200,\n",
    "    \"ff_dimension\": 200,\n",
    "    \"n_attention_heads\": 2,\n",
    "    \"n_encoder_layers\": 0,\n",
    "    \"n_decoder_layers\": 2,\n",
    "    \"dataset\": Dataset.PennTreebank,\n",
    "    \"max_seq_len\": 35,\n",
    "    \"batch_size\": 20,\n",
    "    \"eval_batch_size\": 10,\n",
    "    \"dropout\": 0.2,\n",
    "    \"n_epochs\": 3,\n",
    "    \"loss_criterion\": \"CrossEntropyLoss\"\n",
    "}\n",
    "# validate \n",
    "validate_config(config)\n",
    "\n",
    "# extract config vars\n",
    "embedding_dimension, n_attention_heads, n_encoder_layers, n_decoder_layers, ff_dimension, dropout, batch_size, eval_batch_size = extract_config(config, \"embedding_dimension\", \"n_attention_heads\", \"n_encoder_layers\", \"n_decoder_layers\", \"ff_dimension\", \"dropout\", \"batch_size\", \"eval_batch_size\")\n",
    "\n",
    "\n",
    "# configure device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# load training data\n",
    "train_data, val_data, test_data, vocab = load_data(config)\n",
    "ntokens = len(vocab.stoi)\n",
    "\n",
    "# batch data\n",
    "train_data_batches = batchify(train_data, batch_size, device)\n",
    "val_data_batches = batchify(val_data, eval_batch_size, device)\n",
    "test_data_batches = batchify(test_data, eval_batch_size, device)\n",
    "\n",
    "\n",
    "# instantiate model\n",
    "model = DecoderOnlyTransformer(ntokens, d_model=embedding_dimension, nhead=n_attention_heads, num_encoder_layers=n_encoder_layers, num_decoder_layers=n_decoder_layers, dim_feedforward=ff_dimension, dropout=dropout).to(device)\n",
    "\n",
    "\n",
    "# model = Transformer(embedding_dimension).to(device)\n",
    "\n",
    "\n",
    "# training w/ lightning\n",
    "# trainer = pl.Trainer(gpus=4, num_nodes=8, precision=16, limit_train_batches=0.5)\n",
    "# trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:27y73vde) before initializing another..."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br/>Waiting for W&B process to finish, PID 48049<br/>Program ended successfully."
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ebf6af2b10b42559b90fdd078480f5d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find user logs for this run at: <code>/mnt/github/words2bytes/wandb/run-20210128_233803-27y73vde/logs/debug.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find internal logs for this run at: <code>/mnt/github/words2bytes/wandb/run-20210128_233803-27y73vde/logs/debug-internal.log</code>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                    <br/>Synced <strong style=\"color:#cdcd00\">fluent-donkey-1</strong>: <a href=\"https://wandb.ai/skgbafa/words2btyes/runs/27y73vde\" target=\"_blank\">https://wandb.ai/skgbafa/words2btyes/runs/27y73vde</a><br/>\n                "
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "...Successfully finished last run (ID:27y73vde). Initializing new run:<br/><br/>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.15<br/>\n                Syncing run <strong style=\"color:#cdcd00\">solar-waterfall-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/skgbafa/words2btyes\" target=\"_blank\">https://wandb.ai/skgbafa/words2btyes</a><br/>\n                Run page: <a href=\"https://wandb.ai/skgbafa/words2btyes/runs/2oosbszm\" target=\"_blank\">https://wandb.ai/skgbafa/words2btyes/runs/2oosbszm</a><br/>\n                Run data is saved locally in <code>/mnt/github/words2bytes/wandb/run-20210128_234325-2oosbszm</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"words2btyes\")\n",
    "config = wandb.config\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr = 5.0 # learning rate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, config, epoch, artifacts):\n",
    "    max_seq_len = extract_config(config, \"max_seq_len\")\n",
    "    \n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    src_mask = model.generate_square_subsequent_mask(max_seq_len).to(device)\n",
    "    for batch, i in enumerate(range(0, train_data_batches.size(0) - 1, max_seq_len)):\n",
    "        data, targets = get_batch(max_seq_len, train_data_batches, i)\n",
    "        optimizer.zero_grad()\n",
    "        if data.size(0) != max_seq_len:\n",
    "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "        # print(data.dtype)\n",
    "        # output = model(data, targets)\n",
    "        reshape_seq_len = min(data.size(0), max_seq_len)\n",
    "        targets_flat = targets.reshape(reshape_seq_len, targets.size(0)//reshape_seq_len)\n",
    "        output = model(data, src_mask)\n",
    "        # output = model(data, targets_flat, src_mask)\n",
    "        # output = model(data, targets_flat, src_mask, src_mask)\n",
    "\n",
    "        output.view(-1, ntokens)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        \n",
    "        update_artifact_loss(artifacts, 'training', 'CrossEntropyLoss', epoch, batch, loss.item())\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 200\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data_batches) // max_seq_len, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, data_source, config):\n",
    "    max_seq_len = extract_config(config, \"max_seq_len\")\n",
    "    \n",
    "    model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = model.generate_square_subsequent_mask(max_seq_len).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, data_source.size(0) - 1, max_seq_len):\n",
    "            data, targets = get_batch(max_seq_len, data_source, i)\n",
    "            \n",
    "            # print(data)\n",
    "            # print(targets)\n",
    "            if data.size(0) != max_seq_len:\n",
    "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
    "            # output = model(data, targets)\n",
    "            reshape_seq_len = min(data.size(0), max_seq_len)\n",
    "            targets_flat = targets.reshape(reshape_seq_len, targets.size(0)//reshape_seq_len)\n",
    "            output = model(data, src_mask)\n",
    "            # output = model(data, targets_flat, src_mask, src_mask)\n",
    "            # output = model(data, targets_flat, src_mask, src_mask)\n",
    "\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            loss = criterion(output_flat, targets)\n",
    "            # update_artifact_loss(artifacts, 'training', 'CrossEntropyLoss', epoch, batch, loss.item())\n",
    "            total_loss += len(data) * loss.item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "Key 'n_epochs' not in config",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1aea59027ec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;31m# The number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitalize_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-e9ac728853ac>\u001b[0m in \u001b[0;36minitalize_artifacts\u001b[0;34m(config, train_data_batches, val_data_batches)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# generate/visualize artifacts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minitalize_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_epochs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max_seq_len\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mtraining_cel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_batches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_cel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data_batches\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e8d116520ffe>\u001b[0m in \u001b[0;36mextract_config\u001b[0;34m(config, *argv)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mconfig_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Key '{key}' not in config\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mconfig_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Key 'n_epochs' not in config"
     ]
    }
   ],
   "source": [
    "# train loop\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 3 # The number of epochs\n",
    "best_model = None\n",
    "artifacts = initalize_artifacts(config, train_data_batches, val_data_batches)\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, optimizer, criterion, config, epoch, artifacts)\n",
    "    val_loss = evaluate(model, val_data_batches, config)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
    "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "visualize_artifacts(artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'visualize_artifacts' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f6706569f4d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifacts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'visualize_artifacts' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_artifacts(artifacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=========================================================================================\n| End of training | test loss  5.51 | test ppl   246.15\n=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(best_model, test_data_batches, config)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
    "    test_loss, math.exp(test_loss)))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DecoderOnlyTransformer(\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): CustomTransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=200, out_features=200, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=200, out_features=200, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (1): CustomTransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=200, out_features=200, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=200, out_features=200, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "        (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
       "        (norm1): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.2, inplace=False)\n",
       "        (dropout2): Dropout(p=0.2, inplace=False)\n",
       "        (dropout3): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (to_embedding): Embedding(28783, 200)\n",
       "  (linear): Linear(in_features=200, out_features=28783, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate experiment configs\n",
    "n_attention_heads_range = range(2,6)\n",
    "n_layers_range = range(2,6)\n",
    "experiment_datasets = [ Dataset.PennTreebank, Dataset.WikiText2, Dataset.WikiText103 ]\n",
    "max_seq_len_range = range()\n",
    "embedding_dimension\n",
    "# datasets\n",
    "def generateExperiements():\n",
    "    # for each dataset\n",
    "        # \n",
    "    config = {\n",
    "        \"embedding_dimension\": 200,\n",
    "        \"ff_dimension\": 200,\n",
    "        \"n_attention_heads\": 2,\n",
    "        \"n_encoder_layers\": 2,\n",
    "        \"n_decoder_layers\": 2,\n",
    "        \"dataset\": Dataset.PennTreebank,\n",
    "        \"max_seq_len\": 35,\n",
    "        \"batch_size\": 20,\n",
    "        \"eval_batch_size\": 10,\n",
    "        \"n_epochs\": 3\n",
    "    }\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch lightning experimentation\n",
    "train_dataset, val_dataset, test_dataset, field_processor = load_data_pl(config)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"])\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scaling laws plots\n",
    "    # map config values to scaling laws (model size, compute, dataset size)\n",
    "\n",
    "# scaling laws goals\n",
    "    # predict test loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize attention in encoder and decoder layers\n",
    "# visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb sweep\n",
    "# https://docs.wandb.ai/sweeps/python-api\n",
    "\n",
    "WANDB_ENTITY = \"\"\n",
    "WANDB_PROJECT = \"\"\n",
    "\n",
    "sweep_config = {\n",
    "  \"name\": \"My Sweep\",\n",
    "  \"method\": \"grid\",\n",
    "  \"parameters\": {\n",
    "        \"param1\": {\n",
    "            \"values\": [1, 2, 3]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    run = wandb.init()\n",
    "    print(\"config:\", dict(run.config))\n",
    "    for epoch in range(35):\n",
    "        print(\"running\", epoch)\n",
    "        wandb.log({\"metric\": run.config.param1, \"epoch\": epoch})\n",
    "        time.sleep(1)\n",
    "\n",
    "wandb.agent(sweep_id, function=train)"
   ]
  }
 ]
}