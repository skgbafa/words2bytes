{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('transformer': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d0c581f552870128e643fa5d90873e1c0b3206e5e070517b42e73fec9b0f9803"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *\n",
    "from torchtext import datasets, vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train dataset (IWSLT) has 3634135 tokens in the source language (German) corpus.\n",
      "train dataset (IWSLT) has 3937527 tokens in the target language (English) corpus.\n",
      "val dataset (IWSLT) has 19540 tokens in the source language (German) corpus.\n",
      "val dataset (IWSLT) has 20911 tokens in the target language (English) corpus.\n",
      "Time it took to prepare the data: 3.726960 seconds.\n",
      "Source vocabulary size=58945\n",
      "Target vocabulary size=36322\n",
      "*****\n",
      "Source text:\t"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Batch' object has no attribute 'text'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-909d7dd24f3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Show text from token loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0msample_text_from_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_field_processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_field_processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_token_ids_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/github/words2bytes/utils/data_utils.py\u001b[0m in \u001b[0;36msample_text_from_loader\u001b[0;34m(src_field_processor, trg_field_processor, token_ids_loader, num_samples, sample_src, sample_trg, show_padded)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_src\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Source text:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_ids_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# print only the first example from the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                 \u001b[0msrc_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc_field_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Batch' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_name = DatasetType.IWSLT.name\n",
    "language_direction = LanguageDirection.G2E.name\n",
    "train_token_ids_loader, val_token_ids_loader, src_field_processor, trg_field_processor = get_data_loaders(DATA_DIR_PATH, language_direction, dataset_name, batch_size, device)\n",
    "\n",
    "# Verify that the mask logic is correct\n",
    "pad_token_id = src_field_processor.vocab.stoi[PAD_TOKEN]\n",
    "for batch in train_token_ids_loader:\n",
    "    # Visually inspect that masks make sense\n",
    "    src_padding_mask, trg_mask, num_src_tokens, num_trg_tokens = get_masks_and_count_tokens(batch.src, batch.trg, pad_token_id, device)\n",
    "    break\n",
    "\n",
    "# Check vocab size\n",
    "print(f'Source vocabulary size={len(src_field_processor.vocab)}')\n",
    "print(f'Target vocabulary size={len(trg_field_processor.vocab)}')\n",
    "\n",
    "# Show text from token loader\n",
    "sample_text_from_loader(src_field_processor, trg_field_processor, train_token_ids_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_text_from_loader(src_field_processor, trg_field_processor, token_ids_loader, num_samples=2, sample_src=True, sample_trg=True, show_padded=False):\n",
    "    assert sample_src or sample_trg, f'Either src or trg or both must be enabled.'\n",
    "\n",
    "    for b_idx, token_ids_batch in enumerate(token_ids_loader):\n",
    "        if b_idx == num_samples:  # Number of sentence samples to print\n",
    "            break\n",
    "\n",
    "        print('*' * 5)\n",
    "        if sample_src:\n",
    "            print(\"Source text:\", end=\"\\t\")\n",
    "            for token_id in token_ids_batch.text[0]:  # print only the first example from the batch\n",
    "                src_token = src_field_processor.vocab.itos[token_id]\n",
    "\n",
    "                if src_token == PAD_TOKEN and not show_padded:\n",
    "                    continue\n",
    "\n",
    "                print(src_token, end=\" \")\n",
    "            print()\n",
    "\n",
    "        if sample_trg:\n",
    "            print(\"Target text:\", end=\"\\t\")\n",
    "            for token_id in token_ids_batch.target[0]:\n",
    "                trg_token = trg_field_processor.vocab.itos[token_id]\n",
    "\n",
    "                if trg_token == PAD_TOKEN and not show_padded:\n",
    "                    continue\n",
    "\n",
    "                print(trg_token, end=\" \")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*****\nSource text:\t"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-bbbf644f412a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Source text:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_ids_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# print only the first example from the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0msrc_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msrc_token\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mPAD_TOKEN\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshow_padded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "num_samples = 2\n",
    "sample_src=True\n",
    "sample_trg=True\n",
    "show_padded=False\n",
    "\n",
    "for b_idx, token_ids_batch in enumerate(train_token_ids_loader):\n",
    "    if b_idx == num_samples:  # Number of sentence samples to print\n",
    "        break\n",
    "\n",
    "    print('*' * 5)\n",
    "    if sample_src:\n",
    "        print(\"Source text:\", end=\"\\t\")\n",
    "        for token_id in token_ids_batch.text[0].tolist():  # print only the first example from the batch\n",
    "            src_token = field_processor.vocab.itos[token_id]\n",
    "\n",
    "            if src_token == PAD_TOKEN and not show_padded:\n",
    "                continue\n",
    "\n",
    "            print(src_token, end=\" \")\n",
    "        print()\n",
    "\n",
    "    if sample_trg:\n",
    "        print(\"Target text:\", end=\"\\t\")\n",
    "        for token_id in token_ids_batch.target[0].tolist():\n",
    "            trg_token = field_processor.vocab.itos[token_id]\n",
    "\n",
    "            if trg_token == PAD_TOKEN and not show_padded:\n",
    "                continue\n",
    "\n",
    "            print(trg_token, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9971\n38\n2438\n11\n233\n540\n44\n168\n1453\n115\n30\n478\n0\n128\n9\n9\n313\n1596\n1815\n2\n67\n42\n89\n16\n2\n4\n7133\n331\n573\n8516\n2392\n32\n"
     ]
    }
   ],
   "source": [
    "for token_id in token_ids_batch.text[0].tolist():  # print only the first example from the batch\n",
    "    print(token_id)\n",
    "    # src_token = field_processor.vocab.itos[token_id]\n",
    "    # print(token_id, src_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Time it took to prepare the iterator: 3.347126 seconds.\n"
     ]
    }
   ],
   "source": [
    "def get_data_loaders_causal(dataset_path, dataset_name=DatasetType.PennTreebank.name, batch_size=32, device=None):\n",
    "    ts = time.time()\n",
    "    # prep dataset\n",
    "    dataset = getattr(datasets, dataset_name)  # should not be translation datsets\n",
    "    spacy_en = spacy.load('en')\n",
    "\n",
    "    # prep field processor (vocab)\n",
    "    def tokenizer(text):\n",
    "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "    field_processor = Field(tokenize=tokenizer, init_token=BOS_TOKEN,\n",
    "                            eos_token=EOS_TOKEN, pad_token=PAD_TOKEN, batch_first=True)\n",
    "    \n",
    "    train, validation, test = dataset.splits(text_field=field_processor, root=dataset_path)\n",
    "    field_processor.build_vocab(train, validation, test, min_freq=1)\n",
    "\n",
    "    \n",
    "    # prep iterator\n",
    "    train_token_ids_loader, val_token_ids_loader, test_token_ids_loader = dataset.iters(\n",
    "        batch_size=batch_size, root=dataset_path, device=device)\n",
    "    \n",
    "    # get vocab\n",
    "    # vocabulary = vocab.build_vocab_from_iterator(train_token_ids_loader)\n",
    "    vocabulary = {}\n",
    "    print(f'Time it took to prepare the iterator: {time.time() - ts:3f} seconds.')\n",
    "\n",
    "    return train_token_ids_loader, val_token_ids_loader, field_processor, vocabulary\n",
    "\n",
    "# test\n",
    "batch_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_name = DatasetType.PennTreebank.name\n",
    "train_token_ids_loader, val_token_ids_loader, field_processor, vocabulary = get_data_loaders_causal(DATA_DIR_PATH, dataset_name, batch_size, device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9734\n\n[torchtext.data.batch.Batch of size 32]\n\t[.text]:[torch.cuda.LongTensor of size 35x32 (GPU 0)]\n\t[.target]:[torch.cuda.LongTensor of size 35x32 (GPU 0)]\ntensor([[9971,   38, 2438,  ..., 8516, 2392,   32],\n        [9972,   34,   55,  ...,  564, 2168,    0],\n        [9973,  853, 2156,  ...,    3,    8,   44],\n        ...,\n        [   2,    2,  505,  ...,   15,   88,  184],\n        [ 147, 1031,   14,  ...,   14,   33,  106],\n        [  20,    6,    7,  ...,    6,  846,  402]], device='cuda:0')\ntensor([[9972,   34,   55,  ...,  564, 2168,    0],\n        [9973,  853, 2156,  ...,    3,    8,   44],\n        [9975, 7536,    5,  ...,  225,  204,   50],\n        ...,\n        [ 147, 1031,   14,  ...,   14,   33,  106],\n        [  20,    6,    7,  ...,    6,  846,  402],\n        [   7,  183,  178,  ..., 1344,   35,    0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(len(field_processor.vocab))\n",
    "for batch in train_token_ids_loader:\n",
    "    # Visually inspect that masks make sense\n",
    "    print(batch)\n",
    "    print(batch.text)\n",
    "    print(batch.target)\n",
    "    # src_padding_mask, trg_mask, num_src_tokens, num_trg_tokens = get_masks_and_count_tokens(batch.src, batch.trg, pad_token_id, device)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0lines [00:00, ?lines/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Batch' object has no attribute 'input_fields'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-c7f1dc5d5c03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatasetType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPennTreebank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_token_ids_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_token_ids_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_loaders_causal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Verify that the mask logic is correct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-a2840dfbb6c0>\u001b[0m in \u001b[0;36mget_data_loaders_causal\u001b[0;34m(dataset_path, dataset_name, batch_size, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# get vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_token_ids_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Time it took to prepare the iterator: {time.time() - ts:3f} seconds.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformer/lib/python3.8/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mbuild_vocab_from_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lines'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m             \u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0mword_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformer/lib/python3.8/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    635\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fast path when counter is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformer/lib/python3.8/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_field_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_field_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Batch' object has no attribute 'input_fields'"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_name = DatasetType.PennTreebank.name\n",
    "train_token_ids_loader, val_token_ids_loader, field_processor, vocabulary = get_data_loaders_causal(DATA_DIR_PATH, dataset_name, batch_size, device)\n",
    "\n",
    "# Verify that the mask logic is correct\n",
    "pad_token_id = src_field_processor.vocab.stoi[PAD_TOKEN]\n",
    "for batch in train_token_ids_loader:\n",
    "    # Visually inspect that masks make sense\n",
    "    print(batch)\n",
    "    print(batch.text)\n",
    "    print(batch.target)\n",
    "    # src_padding_mask, trg_mask, num_src_tokens, num_trg_tokens = get_masks_and_count_tokens(batch.src, batch.trg, pad_token_id, device)\n",
    "    break\n",
    "\n",
    "# Check vocab size\n",
    "print(f'Vocabulary size={len(vocabulary)}')\n",
    "# print(f'Target vocabulary size={len(field_processor.vocab)}')\n",
    "\n",
    "# Show text from token loader\n",
    "sample_text_from_loader(field_processor, field_processor, train_token_ids_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, src_field_processor, trg_field_processor = get_datasets_and_vocabs(DATA_DIR_PATH, language_direction, dataset_name == DatasetType.IWSLT.name, use_caching_mechanism=False)\n",
    "trained1 = train_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trained1.examples))\n",
    "\n",
    "print(trained1.examples[1].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trained2.examples[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "Time it took to prepare the data: 2.646358 seconds.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Batch' object has no attribute 'input_fields'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-61457dd85450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_processor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datasets_and_vocab_causal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrained2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-cfd3ec050b1e>\u001b[0m in \u001b[0;36mget_datasets_and_vocab_causal\u001b[0;34m(dataset_path, dataset_name, use_caching_mechanism)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mMIN_FREQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mfield_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMIN_FREQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_processor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformer/lib/python3.8/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                     \u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                     \u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformer/lib/python3.8/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iterable, **kwds)\u001b[0m\n\u001b[1;32m    635\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fast path when counter is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformer/lib/python3.8/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_field_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_field_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Batch' object has no attribute 'input_fields'"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, field_processor = get_datasets_and_vocab_causal(DATA_DIR_PATH)\n",
    "trained2 = train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetType(enum.Enum):\n",
    "    IWSLT = 0,\n",
    "    WMT14 = 1,\n",
    "    PennTreebank = 2,\n",
    "    WikiText2 = 3,\n",
    "    WikiText103 = 4\n",
    "\n",
    "def get_datasets_and_vocab_causal(dataset_path, dataset_name= DatasetType.PennTreebank.name, use_caching_mechanism=False):\n",
    "    # load data\n",
    "    dataset_name= DatasetType.PennTreebank.name\n",
    "    dataset = getattr(datasets, dataset_name) # should not be translation datsets\n",
    "    spacy_en = spacy.load('en_core_web_sm')\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "    field_processor = Field(tokenize=tokenize_en, init_token=BOS_TOKEN, eos_token=EOS_TOKEN, pad_token=PAD_TOKEN, batch_first=True)\n",
    "\n",
    "    # fields = [('src', src_field_processor), ('trg', trg_field_processor)]\n",
    "    # MAX_LEN = 100  # filter out examples that have more than MAX_LEN tokens\n",
    "    # filter_pred = lambda x: len(x.src) <= MAX_LEN and len(x.trg) <= MAX_LEN\n",
    "\n",
    "    # tokenize data\n",
    "    # create datasets\n",
    "    prefix = 'causal_' + dataset_name\n",
    "    train_cache_path = os.path.join(dataset_path, f'{prefix}_train_cache.csv')\n",
    "    val_cache_path = os.path.join(dataset_path, f'{prefix}_val_cache.csv')\n",
    "    test_cache_path = os.path.join(dataset_path, f'{prefix}_test_cache.csv')\n",
    "\n",
    "    # This simple caching mechanism gave me ~30x speedup on my machine! From ~70s -> ~2.5s!\n",
    "    ts = time.time()\n",
    "    if not use_caching_mechanism or not (os.path.exists(train_cache_path) and os.path.exists(val_cache_path)):\n",
    "        train_dataset, val_dataset, test_dataset = dataset.splits(\n",
    "            text_field=field_processor,\n",
    "            root=dataset_path\n",
    "        )\n",
    "        train_dataset, val_dataset, test_dataset = dataset.iters()\n",
    "        # save_cache(train_cache_path, train_dataset)\n",
    "        # save_cache(val_cache_path, val_dataset)\n",
    "        # save_cache(test_cache_path, test_dataset)\n",
    "    else:\n",
    "        # TODO: load from cache \n",
    "        print(\"did not load from cache!\")\n",
    "        return\n",
    "\n",
    "    print(f'Time it took to prepare the data: {time.time() - ts:3f} seconds.')\n",
    "    \n",
    "    MIN_FREQ = 2\n",
    "    field_processor.build_vocab(train_dataset, min_freq=MIN_FREQ)\n",
    "\n",
    "    return train_dataset, val_dataset, field_processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-7ff06faf56a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "splits() missing 1 required positional argument: 'text_field'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-745004c4337c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     eos_token=EOS_TOKEN, pad_token=PAD_TOKEN, batch_first=True)\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfield_processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mfield_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: splits() missing 1 required positional argument: 'text_field'"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "dataset_path = DATA_DIR_PATH\n",
    "dataset_name= DatasetType.PennTreebank.name\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ts = time.time()\n",
    "# prep dataset\n",
    "dataset = getattr(datasets, dataset_name)  # should not be translation datsets\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "# prep field processor (vocab)\n",
    "def tokenizer(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "field_processor = Field(tokenize=tokenizer, init_token=BOS_TOKEN,\n",
    "                    eos_token=EOS_TOKEN, pad_token=PAD_TOKEN, batch_first=True)\n",
    "\n",
    "train, validation, test = dataset.splits(text_field=field_processor, root=dataset_path)\n",
    "field_processor.build_vocab(train, validation, test, min_freq=1)\n",
    "\n",
    "\n",
    "# prep iterator\n",
    "train_token_ids_loader, val_token_ids_loader, test_token_ids_loader = dataset.iters(\n",
    "batch_size=batch_size, root=dataset_path, device=device)\n",
    "\n",
    "# get vocab\n",
    "# vocabulary = vocab.build_vocab_from_iterator(train_token_ids_loader)\n",
    "vocabulary = {}\n",
    "print(f'Time it took to prepare the iterator: {time.time() - ts:3f} seconds.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n[torchtext.data.batch.Batch of size 32]\n\t[.text]:[torch.cuda.LongTensor of size 35x32 (GPU 0)]\n\t[.target]:[torch.cuda.LongTensor of size 35x32 (GPU 0)]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Batch' object has no attribute 'input_fields'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-ab87f1d1cb7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_token_ids_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# vocabulary = vocab.build_vocab_from_iterator()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Batch' object has no attribute 'input_fields'"
     ]
    }
   ],
   "source": [
    "# train.examples[0].text\n",
    "for batch in train_token_ids_loader:\n",
    "    print(batch)\n",
    "    print(batch)\n",
    "    break\n",
    "# vocabulary = vocab.build_vocab_from_iterator()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "st\n",
      "reacting\n",
      "communism\n",
      "damp\n",
      "critic\n",
      "arranging\n",
      "advisers\n",
      "appearances\n",
      "u.s.-soviet\n",
      "terrorism\n",
      "tariffs\n",
      "grow\n",
      "kremlin\n",
      "comparisons\n",
      "gathering\n",
      "readily\n",
      "transform\n",
      "loosen\n",
      "grip\n",
      "suggesting\n",
      "marking\n",
      "bnl\n",
      "fiduciary\n",
      "suitable\n",
      "rome\n",
      "outlined\n",
      "dragging\n",
      "activists\n",
      "gandhi\n",
      "violent\n",
      "disobedience\n",
      "passive\n",
      "webster\n",
      "indians\n",
      "affected\n",
      "truly\n",
      "excuse\n",
      "parks\n",
      "bus\n",
      "illustration\n",
      "tendency\n",
      "gestures\n",
      "posture\n",
      "apt\n",
      "site\n",
      "criminals\n",
      "excitement\n",
      "demonstration\n",
      "speeding\n",
      "dies\n",
      "airing\n",
      "politician\n",
      "cameras\n",
      "phil\n",
      "indirectly\n",
      "vietnam\n",
      "hide\n",
      "fabric\n",
      "enemy\n",
      "cambodia\n",
      "morally\n",
      "draft\n",
      "dignity\n",
      "extraordinarily\n",
      "informed\n",
      "probable\n",
      "calm\n",
      "rational\n",
      "deukmejian\n",
      "repairs\n",
      "quake\n",
      "bipartisan\n",
      "discounting\n",
      "audits\n",
      "pigs\n",
      "update\n",
      "selection\n",
      "specially\n",
      "deductions\n",
      "dependents\n",
      "satisfied\n",
      "overhaul\n",
      "enactment\n",
      "modified\n",
      "backs\n",
      "negligence\n",
      "urges\n",
      "assessment\n",
      "oregon\n",
      "advises\n",
      "mile\n",
      "ira\n",
      "violates\n",
      "delegation\n",
      "rode\n",
      "horses\n",
      "conservation\n",
      "sideline\n",
      "horse\n",
      "inspector\n",
      "arbitrator\n",
      "arbitration\n",
      "burton\n",
      "collect\n",
      "acceptable\n",
      "unwarranted\n",
      "delicate\n",
      "supervisors\n",
      "ironically\n",
      "achenbaum\n",
      "beating\n",
      "worldwide\n",
      "hesitate\n",
      "saatchi\n",
      "hyundai\n",
      "searches\n",
      "invites\n",
      "strokes\n",
      "retire\n",
      "outfit\n",
      "thompson\n",
      "frustrated\n",
      "struck\n",
      "integrate\n",
      "pure\n",
      "accomplish\n",
      "johnston\n",
      "outspoken\n",
      "spots\n",
      "opted\n",
      "macy\n",
      "parade\n",
      "nfl\n",
      "orthodox\n",
      "scene\n",
      "missing\n",
      "deeper\n",
      "prosperity\n",
      "sustain\n",
      "mosbacher\n",
      "deficits\n",
      "satisfy\n",
      "consumed\n",
      "turbulence\n",
      "preserve\n",
      "filipino\n",
      "tries\n",
      "royalties\n",
      "knock\n",
      "khmer\n",
      "rouge\n",
      "levy\n",
      "tumor\n",
      "clinic\n",
      "shocks\n",
      "nerves\n",
      "monitored\n",
      "tragedy\n",
      "probe\n",
      "safer\n",
      "multiple\n",
      "workings\n",
      "finger\n",
      "circuits\n",
      "measuring\n",
      "function\n",
      "clinical\n",
      "stimulate\n",
      "diego\n",
      "handy\n",
      "brains\n",
      "stimulators\n",
      "retrieve\n",
      "seizures\n",
      "sam\n",
      "muscle\n",
      "someday\n",
      "hearts\n",
      "possibilities\n",
      "probing\n",
      "reveal\n",
      "exploring\n",
      "jolted\n",
      "jolt\n",
      "theories\n",
      "jeopardize\n",
      "potent\n",
      "forth\n",
      "palo\n",
      "alto\n",
      "receivables\n",
      "thereafter\n",
      "trustee\n",
      "dizzying\n",
      "musicians\n",
      "perfect\n",
      "wider\n",
      "ocean\n",
      "discipline\n",
      "unpopular\n",
      "revolutionary\n",
      "consume\n",
      "inflows\n",
      "fruit\n",
      "gate\n",
      "appreciate\n",
      "petrochemicals\n",
      "stems\n",
      "leftist\n",
      "trusts\n",
      "bosses\n",
      "catching\n",
      "pledge\n",
      "tumbling\n",
      "pessimistic\n",
      "mildly\n",
      "bullish\n",
      "owen\n",
      "kleinwort\n",
      "benson\n",
      "narrowing\n",
      "influences\n",
      "marked\n",
      "tumble\n",
      "widening\n",
      "knocking\n",
      "predictions\n",
      "regain\n",
      "contended\n",
      "bear\n",
      "culmination\n",
      "hastings\n",
      "repeal\n",
      "helmut\n",
      "tends\n",
      "taxed\n",
      "budgetary\n",
      "coalition\n",
      "mess\n",
      "incidents\n",
      "echo\n",
      "restated\n",
      "monitoring\n",
      "vulnerable\n",
      "assumptions\n",
      "wathen\n",
      "pinkerton\n",
      "encountered\n",
      "olympics\n",
      "divestiture\n",
      "demonstrate\n",
      "lbo\n",
      "unprofitable\n",
      "rid\n",
      "boasts\n",
      "alleges\n",
      "concerning\n",
      "falcon\n",
      "awaited\n",
      "describing\n",
      "ferry\n",
      "method\n",
      "tucker\n",
      "proceed\n",
      "tighten\n",
      "subsidies\n",
      "affluent\n",
      "pot\n",
      "fha\n",
      "insure\n",
      "persuaded\n",
      "sour\n",
      "idle\n",
      "defaults\n",
      "cranston\n",
      "ensuring\n",
      "ink\n",
      "kemp\n",
      "lies\n",
      "hemorrhaging\n",
      "solving\n",
      "gillette\n",
      "tass\n",
      "rubles\n",
      "ruble\n",
      "sequester\n",
      "thoughts\n",
      "frustration\n",
      "pros\n",
      "daffynition\n",
      "applause\n",
      "drilling\n",
      "arkansas\n",
      "seidman\n",
      "rush\n",
      "radical\n",
      "revision\n",
      "gnp\n",
      "eroding\n",
      "surging\n",
      "contentious\n",
      "strikes\n",
      "pittston\n",
      "nynex\n",
      "capitalists\n",
      "false\n",
      "revamping\n",
      "catastrophic\n",
      "medicare\n",
      "medicaid\n",
      "magic\n",
      "bullet\n",
      "sharon\n",
      "nam\n",
      "availability\n",
      "effectiveness\n",
      "guidelines\n",
      "leased\n",
      "employ\n",
      "utah\n",
      "reception\n",
      "hopeful\n",
      "consolidation\n",
      "landscape\n",
      "oppenheimer\n",
      "weyerhaeuser\n",
      "presents\n",
      "dive\n",
      "strengthening\n",
      "boxes\n",
      "exported\n",
      "rod\n",
      "resource\n",
      "lipton\n",
      "rosen\n",
      "katz\n",
      "barring\n",
      "rallied\n",
      "flurry\n",
      "duff\n",
      "phelps\n",
      "soar\n",
      "underscored\n",
      "leaped\n",
      "variations\n",
      "coatings\n",
      "flexible\n",
      "stateswest\n",
      "mesa\n",
      "abandoning\n",
      "pursuit\n",
      "nevada\n",
      "wyoming\n",
      "depress\n",
      "comply\n",
      "tangible\n",
      "ratio\n",
      "celebration\n",
      "anniversary\n",
      "kraft\n",
      "roots\n",
      "blanket\n",
      "shelves\n",
      "tucson\n",
      "themes\n",
      "portraying\n",
      "killer\n",
      "mafia\n",
      "rjr\n",
      "nabisco\n",
      "touting\n",
      "legitimacy\n",
      "doldrums\n",
      "microsoft\n",
      "phenomenon\n",
      "robin\n",
      "dominate\n",
      "rallies\n",
      "outperform\n",
      "hambrecht\n",
      "quist\n",
      "stalled\n",
      "suitor\n",
      "gen\n",
      "chugai\n",
      "delaying\n",
      "outcome\n",
      "sessions\n",
      "prohibition\n",
      "alaska\n",
      "prescribed\n",
      "refinancing\n",
      "subsidized\n",
      "disruptions\n",
      "forge\n",
      "aeronautics\n",
      "satellite\n",
      "nasa\n",
      "room\n",
      "byrd\n",
      "neb\n",
      "denver\n",
      "confusion\n",
      "absence\n",
      "authorization\n",
      "coda\n",
      "consolidate\n",
      "repurchase\n",
      "d\n",
      "ted\n",
      "dedicated\n",
      "loral\n",
      "scenarios\n",
      "stearns\n",
      "presumed\n",
      "contemplating\n",
      "poorer\n",
      "cnw\n",
      "spin\n",
      "belief\n",
      "earthquakes\n",
      "fetch\n",
      "orkem\n",
      "coates\n",
      "spencer\n",
      "lincoln\n",
      "regulator\n",
      "deputies\n",
      "danny\n",
      "panamanian\n",
      "keating\n",
      "meat\n",
      "gonzalez\n",
      "kevin\n",
      "o'connell\n",
      "fraudulent\n",
      "oddly\n",
      "donated\n",
      "recycling\n",
      "aroused\n",
      "erosion\n",
      "discounted\n",
      "footing\n",
      "modernize\n",
      "reverse\n",
      "assurances\n",
      "13-week\n",
      "26-week\n",
      "tenders\n",
      "televised\n",
      "idaho\n",
      "potato\n",
      "cohen\n",
      "boyer\n",
      "bacteria\n",
      "injection\n",
      "genentech\n",
      "insulin\n",
      "diabetics\n",
      "applying\n",
      "lyonnais\n",
      "cie\n",
      "mixte\n",
      "societe\n",
      "financiere\n",
      "unocal\n",
      "refining\n",
      "revolving\n",
      "underwritten\n",
      "terminals\n",
      "streamlining\n",
      "accompanying\n",
      "popularity\n",
      "corresponding\n",
      "offs\n",
      "averages\n",
      "surface\n",
      "psychological\n",
      "cascade\n",
      "pfizer\n",
      "schering\n",
      "plough\n",
      "chevron\n",
      "definitively\n",
      "ogden\n",
      "cilcorp\n",
      "analytical\n",
      "occupied\n",
      "crush\n",
      "confiscated\n",
      "unpaid\n",
      "staged\n",
      "nicaragua\n",
      "condemn\n",
      "cancel\n",
      "managua\n",
      "afghanistan\n",
      "kabul\n",
      "civilian\n",
      "conservatives\n",
      "dissent\n",
      "whites\n",
      "hall\n",
      "vietnamese\n",
      "tanker\n",
      "fairfield\n",
      "preparing\n",
      "diplomat\n",
      "constituents\n",
      "representation\n",
      "constituency\n",
      "convincing\n",
      "mimic\n",
      "revisions\n",
      "geared\n",
      "craig\n",
      "looms\n",
      "miniscribe\n",
      "strategist\n",
      "sharpest\n",
      "tapped\n",
      "pinpoint\n",
      "trough\n",
      "triggering\n",
      "drill\n",
      "contemplated\n",
      "lists\n",
      "calendar\n",
      "tunnel\n",
      "municipals\n",
      "reoffered\n",
      "interpreted\n",
      "prentice\n",
      "electronically\n",
      "governing\n",
      "fasb\n",
      "entities\n",
      "gasb\n",
      "depreciation\n",
      "avery\n",
      "uniroyal\n",
      "intends\n",
      "volumes\n",
      "shelters\n",
      "breath\n",
      "firmer\n",
      "aftershocks\n",
      "creeping\n",
      "fever\n",
      "rescue\n",
      "recessions\n",
      "pepsico\n",
      "cheap\n",
      "flamboyant\n",
      "lows\n",
      "ratios\n",
      "restricted\n",
      "bunch\n",
      "likes\n",
      "ozone\n",
      "negligible\n",
      "birth\n",
      "solar\n",
      "radiation\n",
      "doubtful\n",
      "toxic\n",
      "chlorofluorocarbons\n",
      "depletion\n",
      "earth\n",
      "montreal\n",
      "uv\n",
      "measurements\n",
      "russians\n",
      "max\n",
      "hence\n",
      "greeted\n",
      "credible\n",
      "cfcs\n",
      "subsequently\n",
      "underground\n",
      "epa\n",
      "honest\n",
      "discovery\n",
      "experiments\n",
      "chemistry\n",
      "quotes\n",
      "teagan\n",
      "atmospheric\n",
      "expertise\n",
      "rifenburgh\n",
      "announcements\n",
      "questioning\n",
      "detailing\n",
      "shipment\n",
      "defective\n",
      "coopers\n",
      "flags\n",
      "flaws\n",
      "definition\n",
      "intimate\n",
      "sexual\n",
      "vivid\n",
      "underwriting\n",
      "underwrite\n",
      "challenged\n",
      "approvals\n",
      "treasurys\n",
      "sinyard\n",
      "cycling\n",
      "bike\n",
      "bicycle\n",
      "desks\n",
      "bikes\n",
      "entrepreneurial\n",
      "eidsmo\n",
      "tighter\n",
      "painful\n",
      "lined\n",
      "frame\n",
      "titanium\n",
      "burke\n",
      "taiwanese\n",
      "niche\n",
      "distributors\n",
      "wholly\n",
      "consolidating\n",
      "pfeiffer\n",
      "manufactures\n",
      "mainframes\n",
      "minicomputers\n",
      "franco\n",
      "accumulation\n",
      "consortium\n",
      "conceded\n",
      "channels\n",
      "installation\n",
      "rupert\n",
      "murdoch\n",
      "courtaulds\n",
      "daimler\n",
      "benz\n",
      "advancers\n",
      "unstable\n",
      "ig\n",
      "metall\n",
      "tentative\n",
      "capitalization\n",
      "raiders\n",
      "logical\n",
      "enhance\n",
      "kerry\n",
      "zoete\n",
      "wedd\n",
      "affiliated\n",
      "prevention\n",
      "franklin\n",
      "vacated\n",
      "iron\n",
      "busy\n",
      "burst\n",
      "tonight\n",
      "comptroller\n",
      "hastily\n",
      "narrows\n",
      "widens\n",
      "dated\n",
      "sinking\n",
      "kohlberg\n",
      "kravis\n",
      "roberts\n",
      "carolinas\n",
      "issuance\n",
      "peat\n",
      "adams\n",
      "diagnostic\n",
      "bologna\n",
      "pump\n",
      "technological\n",
      "detect\n",
      "deficiency\n",
      "pitch\n",
      "weaknesses\n",
      "recorders\n",
      "theoretical\n",
      "journalist\n",
      "bets\n",
      "toshiba\n",
      "hurdle\n",
      "credited\n",
      "horrible\n",
      "roper\n",
      "gear\n",
      "fitness\n",
      "intentions\n",
      "doyle\n",
      "desert\n",
      "potatoes\n",
      "bound\n",
      "garden\n",
      "vigorous\n",
      "skiing\n",
      "fad\n",
      "wiped\n",
      "walks\n",
      "leslie\n",
      "bryant\n",
      "bodies\n",
      "bowling\n",
      "endangered\n",
      "commissioned\n",
      "uncertain\n",
      "mills\n",
      "md\n",
      "ghosts\n",
      "haunts\n",
      "skeptics\n",
      "explanation\n",
      "pizza\n",
      "bed\n",
      "dreams\n",
      "hyman\n",
      "celebrating\n",
      "halloween\n",
      "occasion\n",
      "ghost\n",
      "aliens\n",
      "cadillac\n",
      "suits\n",
      "lexington\n",
      "vacuum\n",
      "flew\n",
      "kitchen\n",
      "dog\n",
      "receiver\n",
      "investigated\n",
      "omni\n",
      "shrink\n",
      "carpenter\n",
      "illusion\n",
      "shadow\n",
      "attacked\n",
      "smiling\n",
      "burns\n",
      "sons\n",
      "ken\n",
      "temblor\n",
      "k\n",
      "physicians\n",
      "lets\n",
      "towers\n",
      "burger\n",
      "grades\n",
      "ski\n",
      "debates\n",
      "whoever\n",
      "commanding\n",
      "jose\n",
      "electoral\n",
      "brink\n",
      "platform\n",
      "hedge\n",
      "inefficient\n",
      "uncommon\n",
      "dial\n",
      "interrupted\n",
      "finishing\n",
      "freeze\n",
      "devaluation\n",
      "shield\n",
      "subsidizing\n",
      "runaway\n",
      "humana\n",
      "prevented\n",
      "physician\n",
      "infection\n",
      "nurses\n",
      "ridder\n",
      "nrm\n",
      "restrict\n",
      "distributions\n",
      "cumulative\n",
      "edisto\n",
      "jittery\n",
      "reinvested\n",
      "outflows\n",
      "withdrawals\n",
      "maintains\n",
      "13th\n",
      "buffer\n",
      "wondering\n",
      "minorities\n",
      "abundant\n",
      "hints\n",
      "quayle\n",
      "voiced\n",
      "pouring\n",
      "gatt\n",
      "soap\n",
      "writes\n",
      "unidentified\n",
      "leaks\n",
      "cheney\n",
      "euphoria\n",
      "jordan\n",
      "voter\n",
      "ryder\n",
      "thurmond\n",
      "racial\n",
      "statutes\n",
      "assassination\n",
      "sentences\n",
      "customs\n",
      "boyd\n",
      "ironic\n",
      "statistical\n",
      "considerations\n",
      "relevant\n",
      "severely\n",
      "convictions\n",
      "chancery\n",
      "realistic\n",
      "lone\n",
      "exclusivity\n",
      "adjusters\n",
      "settling\n",
      "epicenter\n",
      "shook\n",
      "rocked\n",
      "shaking\n",
      "carpeting\n",
      "evacuation\n",
      "wrap\n",
      "proceeding\n",
      "fireman\n",
      "rattled\n",
      "morristown\n",
      "forman\n",
      "jackson\n",
      "jeep\n",
      "struggles\n",
      "translate\n",
      "payroll\n",
      "revco\n",
      "bondholders\n",
      "acadia\n",
      "fort\n",
      "woes\n",
      "stein\n",
      "highland\n",
      "cananea\n",
      "mint\n",
      "respective\n",
      "guided\n",
      "demler\n",
      "soybean\n",
      "colombia\n",
      "costa\n",
      "rica\n",
      "colombian\n",
      "cooperatives\n",
      "inevitably\n",
      "politburo\n",
      "demonstrated\n",
      "conform\n",
      "self\n",
      "exercising\n",
      "resolutions\n",
      "wishes\n",
      "solve\n",
      "insufficient\n",
      "conceptual\n",
      "emergence\n",
      "organic\n",
      "blueprint\n",
      "undertaken\n",
      "associations\n",
      "dependent\n",
      "construct\n",
      "heir\n",
      "rein\n",
      "contracting\n",
      "a-1\n",
      "junior\n",
      "profile\n",
      "quotron\n",
      "sweep\n",
      "widen\n",
      "abc\n",
      "incur\n",
      "disrupted\n",
      "broadcast\n",
      "cities\\/abc\n",
      "playoffs\n",
      "pilson\n",
      "decreased\n",
      "streak\n",
      "towel\n",
      "gainers\n",
      "resignations\n",
      "rows\n",
      "concluding\n",
      "poised\n",
      "lotus\n",
      "bureaucrats\n",
      "sits\n",
      "efficiently\n",
      "commonly\n",
      "plug\n",
      "chart\n",
      "disappeared\n",
      "rooms\n",
      "tables\n",
      "contact\n",
      "printer\n",
      "unavailable\n",
      "listen\n",
      "practically\n",
      "explicit\n",
      "subordinates\n",
      "laptop\n",
      "fm\n",
      "compaq\n",
      "specifications\n",
      "blame\n",
      "ru-486\n",
      "surgical\n",
      "swedish\n",
      "bleeding\n",
      "misses\n",
      "pregnancy\n",
      "mortality\n",
      "steering\n",
      "bother\n",
      "contraceptive\n",
      "hoechst\n",
      "prediction\n",
      "legally\n",
      "ignorance\n",
      "supervision\n",
      "aborted\n",
      "furthermore\n",
      "embryo\n",
      "dalkon\n",
      "recording\n",
      "surveys\n",
      "gathered\n",
      "freeman\n",
      "talent\n",
      "reimburse\n",
      "lazard\n",
      "weiss\n",
      "orderly\n",
      "forming\n",
      "ge\n",
      "welch\n",
      "layoffs\n",
      "greenberg\n",
      "crazy\n",
      "catalyst\n",
      "kemper\n",
      "roth\n",
      "supporting\n",
      "shakespeare\n",
      "ourselves\n",
      "strips\n",
      "gould\n",
      "disney\n",
      "sherman\n",
      "sentenced\n",
      "disappearance\n",
      "en\n",
      "transit\n",
      "garcia\n",
      "cocaine\n",
      "republic\n",
      "leipzig\n",
      "cemetery\n",
      "romantic\n",
      "tacked\n",
      "taped\n",
      "conversation\n",
      "paintings\n",
      "dearborn\n",
      "noise\n",
      "warranty\n",
      "guaranty\n",
      "termination\n",
      "assumes\n",
      "donating\n",
      "messages\n",
      "donations\n",
      "hat\n",
      "rank\n",
      "devastation\n",
      "charleston\n",
      "instant\n",
      "dip\n",
      "woo\n",
      "charity\n",
      "chasing\n",
      "barry\n",
      "earmarked\n",
      "franchisees\n",
      "sponsored\n",
      "refusing\n",
      "squibb\n",
      "fda\n",
      "inability\n",
      "limitations\n",
      "award\n",
      "dangers\n",
      "rejecting\n",
      "appealed\n",
      "nestle\n",
      "conclusion\n",
      "topple\n",
      "mandate\n",
      "highways\n",
      "foes\n",
      "terrible\n",
      "justifies\n",
      "c\n",
      "wire\n",
      "traffickers\n",
      "laundering\n",
      "identifying\n",
      "recipients\n",
      "facsimile\n",
      "tpa\n",
      "hardest\n",
      "ralph\n",
      "awaiting\n",
      "closings\n",
      "casualty\n",
      "vogelstein\n",
      "colon\n",
      "deadly\n",
      "suppressor\n",
      "prone\n",
      "retinoblastoma\n",
      "p53\n",
      "chromosome\n",
      "analyzing\n",
      "fox\n",
      "experiment\n",
      "eric\n",
      "confusing\n",
      "confirming\n",
      "hughes\n",
      "levine\n",
      "mice\n",
      "labs\n",
      "rushing\n",
      "bristol\n",
      "myers\n",
      "accuse\n",
      "replied\n",
      "peladeau\n",
      "quebecor\n",
      "supplement\n",
      "thomson\n",
      "distributing\n",
      "z\n",
      "manitoba\n",
      "searle\n",
      "rubin\n",
      "unlawful\n",
      "omnibus\n",
      "vigorously\n",
      "hancock\n",
      "kelly\n",
      "tops\n",
      "resumed\n",
      "oral\n",
      "terminate\n",
      "nonsense\n",
      "coach\n",
      "doug\n",
      "mediator\n",
      "mighty\n",
      "deferred\n",
      "b-2\n",
      "tactical\n",
      "fighter\n",
      "accords\n",
      "wichita\n",
      "kan\n",
      "helicopter\n",
      "hourly\n",
      "reiterated\n",
      "aluminum\n",
      "1\\/2-year\n",
      "grounds\n",
      "arctic\n",
      "calgary\n",
      "alberta\n",
      "vancouver\n",
      "kick\n",
      "mackenzie\n",
      "transcanada\n",
      "tenneco\n",
      "alaskan\n",
      "connecting\n",
      "counties\n",
      "deferring\n",
      "finish\n",
      "ernst\n",
      "remics\n",
      "rochester\n",
      "a$\n",
      "allianz\n",
      "reinforced\n",
      "dresdner\n",
      "commerzbank\n",
      "canceled\n",
      "regrets\n",
      "noranda\n",
      "carol\n",
      "fletcher\n",
      "amoco\n",
      "undeveloped\n",
      "monitors\n",
      "disks\n",
      "freely\n",
      "prepayments\n",
      "bancroft\n",
      "treasurer\n",
      "patterson\n",
      "wendy\n",
      "midler\n",
      "backup\n",
      "distinctive\n",
      "spawned\n",
      "bobby\n",
      "mack\n",
      "vitro\n",
      "spate\n",
      "hunting\n",
      "teeth\n",
      "tailspin\n",
      "margaret\n",
      "ems\n",
      "omaha\n",
      "egon\n",
      "arab\n",
      "apartheid\n",
      "fluor\n",
      "prevail\n",
      "insurers\n",
      "swell\n",
      "corr\n",
      "telesis\n",
      "deductible\n",
      "prelude\n",
      "splitting\n",
      "breakup\n",
      "reinforce\n",
      "phased\n",
      "transatlantic\n",
      "generates\n",
      "outperformed\n",
      "prompting\n",
      "honeywell\n",
      "col\n",
      "figuring\n",
      "mccall\n",
      "pearce\n",
      "simpson\n",
      "arabs\n",
      "sidhpur\n",
      "fame\n",
      "psyllium\n",
      "patel\n",
      "centuries\n",
      "folk\n",
      "ciba\n",
      "geigy\n",
      "p&g\n",
      "displayed\n",
      "kellogg\n",
      "marginal\n",
      "middlemen\n",
      "glad\n",
      "crest\n",
      "sr\n",
      "reasonable\n",
      "waxman\n",
      "overly\n",
      "mild\n",
      "priorities\n",
      "prohibit\n",
      "mandated\n",
      "reinsurance\n",
      "belgian\n",
      "provisional\n",
      "nashua\n",
      "slumped\n",
      "outsider\n",
      "proclaimed\n",
      "titled\n",
      "carr\n",
      "regained\n",
      "marxist\n",
      "sovereignty\n",
      "arose\n",
      "emigration\n",
      "uneasy\n",
      "averaging\n",
      "shock\n",
      "flavor\n",
      "baring\n",
      "fallout\n",
      "govern\n",
      "refugees\n",
      "repression\n",
      "projection\n",
      "seng\n",
      "consequently\n",
      "fisher\n",
      "artificially\n",
      "coordination\n",
      "episode\n",
      "decent\n",
      "ben\n",
      "attitudes\n",
      "sohmer\n",
      "pbs\n",
      "jewish\n",
      "kate\n",
      "thrust\n",
      "outset\n",
      "guess\n",
      "naked\n",
      "motel\n",
      "crossland\n",
      "revise\n",
      "afloat\n",
      "intensely\n",
      "input\n",
      "relocation\n",
      "shippers\n",
      "ivy\n",
      "shoppers\n",
      "coats\n",
      "photo\n",
      "rainbow\n",
      "loud\n",
      "roberti\n",
      "observes\n",
      "paterson\n",
      "casual\n",
      "unused\n",
      "abruptly\n",
      "mtm\n",
      "tvs\n",
      "blues\n",
      "gatward\n",
      "broadcasters\n",
      "connaught\n",
      "vaccine\n",
      "merieux\n",
      "chiron\n",
      "corner\n",
      "peru\n",
      "mineral\n",
      "expiration\n",
      "avondale\n",
      "sutton\n",
      "concord\n",
      "gang\n",
      "characteristic\n",
      "amex\n",
      "ufo\n",
      "timothy\n",
      "beam\n",
      "hell\n",
      "destroying\n",
      "shooting\n",
      "memorandum\n",
      "californians\n",
      "beings\n",
      "robot\n",
      "universe\n",
      "russia\n",
      "radar\n",
      "sverdlovsk\n",
      "debris\n",
      "creatures\n",
      "rocky\n",
      "trustcorp\n",
      "akzo\n",
      "bergsma\n",
      "alliances\n",
      "petrochemical\n",
      "bleak\n",
      "universal\n",
      "captured\n",
      "guardian\n",
      "reveals\n",
      "divide\n",
      "camps\n",
      "stabilize\n",
      "stabilizing\n",
      "aggregates\n",
      "deployed\n",
      "chorus\n",
      "tie\n",
      "surrounded\n",
      "freed\n",
      "rampant\n",
      "natwest\n",
      "delegate\n",
      "heller\n",
      "wcrs\n",
      "della\n",
      "femina\n",
      "mcnamee\n",
      "reebok\n",
      "hedges\n",
      "r.h\n",
      "federated\n",
      "bullock\n",
      "finkelstein\n",
      "viability\n",
      "altman\n",
      "teller\n",
      "chains\n",
      "bloomingdale\n",
      "saks\n",
      "windows\n",
      "candy\n",
      "kkr\n",
      "aetna\n",
      "catastrophe\n",
      "township\n",
      "anc\n",
      "unity\n",
      "sisulu\n",
      "shouted\n",
      "westinghouse\n",
      "steam\n",
      "combustion\n",
      "supplied\n",
      "asea\n",
      "boveri\n",
      "renaissance\n",
      "marous\n",
      "richter\n",
      "pale\n",
      "propelled\n",
      "unfriendly\n",
      "victories\n",
      "joke\n",
      "inning\n",
      "stir\n",
      "scored\n",
      "terry\n",
      "prevailed\n",
      "kirk\n",
      "homer\n",
      "twelve\n",
      "rationale\n",
      "grumman\n",
      "scheduling\n",
      "concludes\n",
      "estimating\n",
      "mentality\n",
      "deadlines\n",
      "burlington\n",
      "taping\n",
      "audio\n",
      "resale\n",
      "raider\n",
      "werner\n",
      "coup\n",
      "bally\n",
      "jean\n",
      "airplanes\n",
      "grenfell\n",
      "cocom\n",
      "deserves\n",
      "unisys\n",
      "sheer\n",
      "worrisome\n",
      "approaching\n",
      "straszheim\n",
      "commentary\n",
      "newsletter\n",
      "annuities\n",
      "threaten\n",
      "prisoner\n",
      "trusted\n",
      "denounced\n",
      "thrown\n",
      "reunification\n",
      "neutral\n",
      "broderick\n",
      "rental\n",
      "fatal\n",
      "perlman\n",
      "ignore\n",
      "commute\n",
      "criticisms\n",
      "harbor\n",
      "keen\n",
      "neatly\n",
      "greens\n",
      "necessity\n",
      "neighbor\n",
      "venice\n",
      "catalog\n",
      "translated\n",
      "daewoo\n",
      "sri\n",
      "koreans\n",
      "daly\n",
      "semel\n",
      "hanging\n",
      "canton\n",
      "kurt\n",
      "cleaning\n",
      "mgm\\/ua\n",
      "encouragement\n",
      "suburb\n",
      "darman\n",
      "reminder\n",
      "divisive\n",
      "cms\n",
      "polly\n",
      "sansui\n",
      "adjust\n",
      "offshore\n",
      "competitiveness\n",
      "doubling\n",
      "bellsouth\n",
      "lin\n",
      "mccaw\n",
      "payout\n",
      "flawed\n",
      "declares\n",
      "affects\n",
      "attributable\n",
      "dapuzzo\n",
      "tele\n",
      "resilience\n",
      "upheaval\n",
      "warburg\n",
      "hanson\n",
      "von\n",
      "humanitarian\n",
      "staging\n",
      "flaw\n",
      "installations\n",
      "scrap\n",
      "afghan\n",
      "roads\n",
      "aoun\n",
      "syrian\n",
      "pullout\n",
      "championship\n",
      "unilever\n",
      "nervously\n",
      "faberge\n",
      "noxell\n",
      "makeup\n",
      "detergent\n",
      "lauder\n",
      "artistic\n",
      "rolls\n",
      "nationally\n",
      "coupons\n",
      "aged\n",
      "supermarkets\n",
      "ordinarily\n",
      "colgate\n",
      "palmolive\n",
      "covert\n",
      "14-year\n",
      "wipe\n",
      "coups\n",
      "dictator\n",
      "endanger\n",
      "boren\n",
      "sens\n",
      "specter\n",
      "internationally\n",
      "harbors\n",
      "the-13th\n",
      "gte\n",
      "rand\n",
      "besieged\n",
      "maneuver\n",
      "reinforcing\n",
      "tim\n",
      "ages\n",
      "veterans\n",
      "youngest\n",
      "korotich\n",
      "educate\n",
      "cheered\n",
      "recognizes\n",
      "honesty\n",
      "cynthia\n",
      "greenspan\n",
      "chris\n",
      "dodd\n",
      "accelerate\n",
      "infringement\n",
      "misstated\n",
      "racked\n",
      "cathcart\n",
      "mall\n",
      "incorrectly\n",
      "luzon\n",
      "polyethylene\n",
      "mateo\n",
      "speaker\n",
      "waves\n",
      "marlin\n",
      "fitzwater\n",
      "restoring\n",
      "buried\n",
      "bart\n",
      "hertz\n",
      "bracing\n",
      "listings\n",
      "quantum\n",
      "istat\n",
      "banco\n",
      "exterior\n",
      "privatization\n",
      "pesetas\n",
      "technicians\n",
      "prosecutions\n",
      "conclusions\n",
      "bono\n",
      "justin\n",
      "pretrial\n",
      "grossly\n",
      "ron\n",
      "conspiring\n",
      "wildlife\n",
      "spill\n",
      "havoc\n",
      "instantly\n",
      "jamie\n",
      "whitten\n",
      "remark\n",
      "restraint\n",
      "rican\n",
      "arias\n",
      "interpret\n",
      "wyss\n",
      "totals\n",
      "mega\n",
      "prospectus\n",
      "larsen\n",
      "toubro\n",
      "oversubscribed\n",
      "ministries\n",
      "nathan\n",
      "brewer\n",
      "finnair\n",
      "archrival\n",
      "abbie\n",
      "activist\n",
      "script\n",
      "chung\n",
      "actors\n",
      "benjamin\n",
      "stops\n",
      "theater\n",
      "syndicated\n",
      "joan\n",
      "drama\n",
      "dentsu\n",
      "eurocom\n",
      "corning\n",
      "comedy\n",
      "grid\n",
      "heavier\n",
      "census\n",
      "sears\n",
      "roebuck\n",
      "mart\n",
      "weakest\n",
      "explosions\n",
      "destroyed\n",
      "catastrophes\n",
      "syndicates\n",
      "leaseway\n",
      "equation\n",
      "slipping\n",
      "periodic\n",
      "diverted\n",
      "midst\n",
      "sandinistas\n",
      "abrams\n",
      "bernard\n",
      "petrie\n",
      "deb\n",
      "unanimously\n",
      "liquidate\n",
      "jayark\n",
      "cftc\n",
      "comex\n",
      "conway\n",
      "pits\n",
      "24-hour\n",
      "react\n",
      "attribute\n",
      "dire\n",
      "recommends\n",
      "absorb\n",
      "scramble\n",
      "crumbling\n",
      "mayoral\n",
      "unloading\n",
      "spree\n",
      "lockheed\n",
      "innopac\n",
      "mobil\n",
      "yards\n",
      "jokes\n",
      "caterpillar\n",
      "whittle\n",
      "dillon\n",
      "octel\n",
      "e\n",
      "revealed\n",
      "briefly\n",
      "scary\n",
      "connolly\n",
      "lbos\n",
      "troubling\n",
      "disappointments\n",
      "richfield\n",
      "faa\n",
      "temperatures\n",
      "flooding\n",
      "coastal\n",
      "atoms\n",
      "dioxide\n",
      "burning\n",
      "fossil\n",
      "chairmen\n",
      "foley\n",
      "subsidy\n",
      "fortunately\n",
      "mainstream\n",
      "parental\n",
      "apartments\n",
      "plumbing\n",
      "schaeffer\n",
      "vanguard\n",
      "compounded\n",
      "shifting\n",
      "toseland\n",
      "hypoglycemia\n",
      "costing\n",
      "strategists\n",
      "ivory\n",
      "wsj\n",
      "baseline\n",
      "chiefs\n",
      "strengths\n",
      "discouraged\n",
      "confirmation\n",
      "softness\n",
      "disabilities\n",
      "disabled\n",
      "handicapped\n",
      "deliberations\n",
      "addressed\n",
      "aspirations\n",
      "eurodollar\n",
      "envy\n",
      "shanghai\n",
      "chartered\n",
      "hk$\n",
      "defaulted\n",
      "taxi\n",
      "bullion\n",
      "processed\n",
      "noncallable\n",
      "tampa\n",
      "bausch\n",
      "lenses\n",
      "jolla\n",
      "southwest\n",
      "vincent\n",
      "preceding\n",
      "generale\n",
      "lubricants\n",
      "manic\n",
      "phones\n",
      "bsn\n",
      "fleming\n",
      "trinova\n",
      "biological\n",
      "bacterium\n",
      "diversity\n",
      "bruno\n",
      "pile\n",
      "dunes\n",
      "yard\n",
      "mideast\n",
      "exporting\n",
      "opec\n",
      "cox\n",
      "roller\n",
      "coaster\n",
      "gallons\n",
      "pitched\n",
      "persian\n",
      "iranian\n",
      "rig\n",
      "southwestern\n",
      "boat\n",
      "dun\n",
      "bradstreet\n",
      "setbacks\n",
      "arrow\n",
      "supervisor\n",
      "vault\n",
      "gardens\n",
      "dorfman\n",
      "conner\n",
      "texans\n",
      "attendants\n",
      "controllers\n",
      "indexation\n",
      "supplying\n",
      "poughkeepsie\n",
      "whooping\n",
      "cough\n",
      "pertussis\n",
      "toxin\n",
      "rothschilds\n",
      "glare\n",
      "19th\n",
      "recalled\n",
      "mainstay\n",
      "erich\n",
      "buffett\n",
      "outweigh\n",
      "defenders\n",
      "blaming\n",
      "fares\n",
      "ab\n",
      "skf\n",
      "kronor\n",
      "bearings\n",
      "redford\n",
      "environmentally\n",
      "environmentalism\n",
      "windsor\n",
      "ncaa\n",
      "athletes\n",
      "basketball\n",
      "coaches\n",
      "portrait\n",
      "mad\n",
      "pencils\n",
      "circus\n",
      "fdic\n",
      "refined\n",
      "agip\n",
      "libya\n",
      "upgrading\n",
      "refineries\n",
      "kuwait\n",
      "academy\n",
      "engelken\n",
      "clutter\n",
      "shouting\n",
      "lifetime\n",
      "reads\n",
      "turnpike\n",
      "southam\n",
      "norton\n",
      "eastman\n",
      "roh\n",
      "ordinance\n",
      "espectador\n",
      "custody\n",
      "koch\n",
      "opponent\n",
      "roadways\n",
      "carson\n",
      "withheld\n",
      "endorsement\n",
      "incinerator\n",
      "leventhal\n",
      "flom\n",
      "determination\n",
      "adjuster\n",
      "policyholders\n",
      "rubble\n",
      "parcel\n",
      "shattered\n",
      "hammack\n",
      "assessing\n",
      "dealt\n",
      "linear\n",
      "reviews\n",
      "gently\n",
      "roadway\n",
      "fcc\n",
      "commissioners\n",
      "brouwer\n",
      "tremors\n",
      "lipper\n",
      "anticipate\n",
      "deflator\n",
      "nutritional\n",
      "assassinations\n",
      "grave\n",
      "abuses\n",
      "gridlock\n",
      "remembered\n",
      "accustomed\n",
      "lacking\n",
      "turner\n",
      "mo\n",
      "newark\n",
      "plain\n",
      "horn\n",
      "resorts\n",
      "qintex\n",
      "skase\n",
      "antar\n",
      "seizure\n",
      "forfeiture\n",
      "tainted\n",
      "applies\n",
      "correction\n",
      "widened\n",
      "accelerating\n",
      "pumped\n",
      "gun\n",
      "workstations\n",
      "fabrication\n",
      "ranch\n",
      "willful\n",
      "mahfouz\n",
      "cairo\n",
      "novels\n",
      "span\n",
      "colonial\n",
      "bureaucrat\n",
      "experimental\n",
      "endure\n",
      "poorest\n",
      "norwood\n",
      "weirton\n",
      "restoration\n",
      "leverage\n",
      "northrop\n",
      "iverson\n",
      "thriving\n",
      "dynamic\n",
      "morishita\n",
      "gallery\n",
      "christies\n",
      "aichi\n",
      "holmes\n",
      "wherever\n",
      "nonperforming\n",
      "batibot\n",
      "decker\n",
      "emhart\n",
      "fournier\n",
      "defer\n",
      "pinnacle\n",
      "traub\n",
      "vatican\n",
      "pope\n",
      "distribute\n",
      "unscrupulous\n",
      "collectors\n",
      "giorgio\n",
      "dig\n",
      "notification\n",
      "ernest\n",
      "jefferies\n",
      "bakker\n",
      "helmsley\n",
      "bottled\n",
      "packwood\n",
      "tuition\n",
      "marsh\n",
      "mclennan\n",
      "peripherals\n",
      "wang\n",
      "trucking\n",
      "allowance\n",
      "landed\n",
      "deaver\n",
      "shannon\n",
      "confessed\n",
      "perjury\n",
      "topiary\n",
      "retreated\n",
      "lavelle\n",
      "acquitted\n",
      "cuba\n",
      "oas\n",
      "guinness\n",
      "fish\n",
      "burmah\n",
      "refiners\n",
      "benefiting\n",
      "edgar\n",
      "mitterrand\n",
      "ohbayashi\n",
      "schwarz\n",
      "farrell\n",
      "posner\n",
      "reconciliation\n",
      "epo\n",
      "amgen\n",
      "conception\n",
      "tier\n",
      "circulating\n",
      "kodak\n",
      "maynard\n",
      "armonk\n",
      "stunning\n",
      "abm\n",
      "krasnoyarsk\n",
      "cineplex\n",
      "odeon\n",
      "drabinsky\n",
      "cherry\n",
      "workstation\n",
      "bare\n",
      "leval\n",
      "salinger\n",
      "remedy\n",
      "oakes\n",
      "masson\n",
      "admission\n",
      "dishonesty\n",
      "smart\n",
      "atlas\n",
      "arby\n",
      "franchisers\n",
      "seabrook\n",
      "renault\n",
      "panels\n",
      "pwa\n",
      "airbus\n",
      "bartlett\n",
      "ethiopia\n",
      "aeroflot\n",
      "vila\n",
      "pesticide\n",
      "pesticides\n",
      "hazard\n",
      "extract\n",
      "trapped\n",
      "relying\n",
      "dogged\n",
      "sporadic\n",
      "delmed\n",
      "dialysis\n",
      "ehrlich\n",
      "fresenius\n",
      "coins\n",
      "coin\n",
      "cooling\n",
      "coping\n",
      "constructed\n",
      "woods\n",
      "expenditure\n",
      "mit\n",
      "entrepreneurs\n",
      "edt\n",
      "broadway\n",
      "hbo\n",
      "showtime\n",
      "s\n",
      "benton\n",
      "merksamer\n",
      "jewelers\n",
      "l.j\n",
      "hooker\n",
      "switches\n",
      "arrange\n",
      "hectic\n",
      "ramada\n",
      "drawings\n",
      "shy\n",
      "bpca\n",
      "cornell\n",
      "incorrect\n",
      "revoke\n",
      "patience\n",
      "bronner\n",
      "interactive\n",
      "mushrooms\n",
      "medication\n",
      "mirage\n",
      "nugget\n",
      "hilton\n",
      "casinos\n",
      "mom\n",
      "influx\n",
      "suites\n",
      "proliferation\n",
      "overbuilt\n",
      "foreclosed\n",
      "mouth\n",
      "recreation\n",
      "armco\n",
      "jacobson\n",
      "provigo\n",
      "lortie\n",
      "nadeau\n",
      "showroom\n",
      "aided\n",
      "nye\n",
      "anheuser\n",
      "beneath\n",
      "brewery\n",
      "zeta\n",
      "seal\n",
      "cboe\n",
      "undoubtedly\n",
      "utilization\n",
      "h.h\n",
      "ivan\n",
      "boesky\n",
      "cutler\n",
      "ferguson\n",
      "plaintiff\n",
      "simpler\n",
      "businessland\n",
      "schwartz\n",
      "esselte\n",
      "f-14\n",
      "menlo\n",
      "slim\n",
      "butcher\n",
      "tw\n",
      "battled\n",
      "usair\n",
      "importing\n",
      "daikin\n",
      "azt\n",
      "usage\n",
      "pediatric\n",
      "infected\n",
      "subpoena\n",
      "jeff\n",
      "uncle\n",
      "chicken\n",
      "dlj\n",
      "\\\n",
      "*\n",
      "\\*\\\n",
      "espn\n",
      "tisch\n",
      "bitterly\n",
      "meredith\n",
      "lineup\n",
      "comsat\n",
      "bozell\n",
      "eroded\n",
      "dictaphone\n",
      "salesmen\n",
      "shack\n",
      "vax\n",
      "fried\n",
      "haas\n",
      "laff\n",
      "lang\n",
      "lorin\n",
      "claimants\n",
      "robins\n",
      "ingersoll\n",
      "fleets\n",
      "maxicare\n",
      "saab\n",
      "scania\n",
      "superfund\n",
      "micro\n",
      "quickview\n",
      "programmers\n",
      "cupertino\n",
      "kageyama\n",
      "motivated\n",
      "fusion\n",
      "roe\n",
      "wade\n",
      "dispatched\n",
      "curbs\n",
      "goodyear\n",
      "roderick\n",
      "corry\n",
      "minimills\n",
      "thoroughbred\n",
      "lynn\n",
      "breathing\n",
      "terrorist\n",
      "shamir\n",
      "glazer\n",
      "bookings\n",
      "adm\n",
      "capita\n",
      "ldp\n",
      "commuters\n",
      "diet\n",
      "carat\n",
      "diamonds\n",
      "thick\n",
      "deduction\n",
      "geographic\n",
      "sheraton\n",
      "gorky\n",
      "delicious\n",
      "fujis\n",
      "worm\n",
      "gerrymandering\n",
      "legislatures\n",
      "tro\n",
      "adobe\n",
      "openness\n",
      "anthrax\n",
      "peasant\n",
      "dying\n",
      "peasants\n",
      "fertilizer\n",
      "poles\n",
      "naczelnik\n",
      "urgency\n",
      "centered\n",
      "prosecutorial\n",
      "opera\n",
      "violetta\n",
      "wooden\n",
      "festival\n",
      "madrid\n",
      "convex\n",
      "unfavorable\n",
      "inspectors\n",
      "wonderful\n",
      "whittington\n",
      "planet\n",
      "cypress\n",
      "parkway\n",
      "codes\n",
      "bogart\n",
      "theatrical\n",
      "shea\n",
      "esb\n",
      "inco\n",
      "homefed\n",
      "pepsi\n",
      "murata\n",
      "vickers\n",
      "pons\n",
      "reputable\n",
      "bebear\n",
      "axa\n",
      "applicants\n",
      "imo\n",
      "arena\n",
      "berry\n",
      "apogee\n",
      "a.m\n",
      "kaiser\n",
      "storer\n",
      "con\n",
      "rubbermaid\n",
      "mmi\n",
      "asarco\n",
      "h.f\n",
      "ahmanson\n",
      "vista\n",
      "cubs\n",
      "refcorp\n",
      "swung\n",
      "mouse\n",
      "yeast\n",
      "arteries\n",
      "artery\n",
      "gum\n",
      "irish\n",
      "merkur\n",
      "scorpio\n",
      "francis\n",
      "wachovia\n",
      "antibody\n",
      "competent\n",
      "kohl\n",
      "olivetti\n",
      "conasupo\n",
      "fernandez\n",
      "cans\n",
      "probability\n",
      "crandall\n",
      "digest\n",
      "grey\n",
      "advertiser\n",
      "vinson\n",
      "jurors\n",
      "artists\n",
      "massage\n",
      "refrigerators\n",
      "freeways\n",
      "subway\n",
      "kasparov\n",
      "d.t\n",
      "notorious\n",
      "pawn\n",
      "blumenfeld\n",
      "bourbon\n",
      "whiskey\n",
      "garratt\n",
      "ecological\n",
      "legent\n",
      "underestimated\n",
      "clinton\n",
      "tesoro\n",
      "eagle\n",
      "conservatorship\n",
      "incompetent\n",
      "boiler\n",
      "permanently\n",
      "ashland\n",
      "lyondell\n",
      "agricole\n",
      "downey\n",
      "cnbc\n",
      "merabank\n",
      "goodson\n",
      "sorrell\n",
      "mattel\n",
      "suez\n",
      "savaiko\n",
      "palladium\n",
      "curve\n",
      "emerson\n",
      "fujisawa\n",
      "enviropact\n",
      "fazio\n",
      "atlantis\n",
      "galileo\n",
      "detrex\n",
      "guideline\n",
      "volokh\n",
      "polaroid\n",
      "prefers\n",
      "nuovo\n",
      "ambrosiano\n",
      "translation\n",
      "southmark\n",
      "rhone\n",
      "poulenc\n",
      "hdtv\n",
      "pachinko\n",
      "mcduffie\n",
      "recital\n",
      "violin\n",
      "durkin\n",
      "maidenform\n",
      "brawer\n",
      "lesk\n",
      "rosenthal\n",
      "ups\n",
      "impeachment\n",
      "mancuso\n",
      "h&r\n",
      "nsc\n",
      "briggs\n",
      "bureaus\n",
      "sperry\n",
      "lesko\n",
      "intensify\n",
      "cowboys\n",
      "cuban\n",
      "cubans\n",
      "seita\n",
      "preamble\n",
      "barre\n",
      "somalia\n",
      "runway\n",
      "mengistu\n",
      "rafale\n",
      "goupil\n",
      "crusaders\n",
      "dassault\n",
      "cathay\n",
      "eddington\n",
      "lufthansa\n",
      "agnos\n",
      "bursts\n",
      "massages\n",
      "cafeteria\n",
      "slauson\n",
      "watts\n",
      "detectors\n",
      "zones\n",
      "banponce\n",
      "ortiz\n",
      "salespeople\n",
      "mcdonough\n",
      "carpets\n",
      "ducks\n",
      "ferranti\n",
      "realist\n",
      "winnebago\n",
      "stabilized\n",
      "tva\n",
      "ekco\n",
      "nora\n",
      "shv\n",
      "banc\n",
      "190.58-point\n",
      "anacomp\n",
      "comair\n",
      "quack\n",
      "mansion\n",
      "a.p\n",
      "trelleborg\n",
      "falconbridge\n",
      "enserch\n",
      "picop\n",
      "imf\n",
      "tremor\n",
      "spacecraft\n",
      "honecker\n",
      "tritium\n",
      "fleischmann\n",
      "feedlots\n",
      "hut\n",
      "deloitte\n",
      "haskins\n",
      "iafp\n",
      "peterson\n",
      "median\n",
      "u\n",
      "tharp\n",
      "enforcers\n",
      "provinces\n",
      "rorer\n",
      "merck\n",
      "soo\n",
      "xtra\n",
      "gintel\n",
      "hasbro\n",
      "d'arcy\n",
      "fur\n",
      "furriers\n",
      "furs\n",
      "mink\n",
      "jackets\n",
      "hepatitis\n",
      "westridge\n",
      "nguyen\n",
      "chan\n",
      "thi\n",
      "bumiputra\n",
      "basir\n",
      "m$\n",
      "plummet\n",
      "skiers\n",
      "outer\n",
      "contested\n",
      "seismic\n",
      "callable\n",
      "newsletters\n",
      "westmoreland\n",
      "devoe\n",
      "erased\n",
      "marlowe\n",
      "cela\n",
      "nimitz\n",
      "reinforcement\n",
      "bonn\n",
      "isler\n",
      "skipper\n",
      "mural\n",
      "hoelzer\n",
      "belli\n",
      "andreas\n",
      "prisons\n",
      "shutdown\n",
      "gaubert\n",
      "moss\n",
      "cruz\n",
      "fema\n",
      "biscuits\n",
      "doman\n",
      "amdura\n",
      "commerciale\n",
      "discovision\n",
      "cherokee\n",
      "jupiter\n",
      "dayton\n",
      "corsica\n",
      "beretta\n",
      "enron\n",
      "verwoerd\n",
      "morgenzon\n",
      "guzman\n",
      "cabrera\n",
      "quina\n",
      "pemex\n",
      "daf\n",
      "whitbread\n",
      "beefeater\n",
      "gin\n",
      "redmond\n",
      "salmonella\n",
      "capcom\n",
      "jal\n",
      "petco\n",
      "fossett\n",
      "equitec\n",
      "steinhardt\n",
      "arkla\n",
      "caltrans\n",
      "lionel\n",
      "caffeine\n",
      "bork\n",
      "fk-506\n",
      "laband\n",
      "steppenwolf\n",
      "sagan\n",
      "templeton\n",
      "beebes\n",
      "craven\n",
      "firstsouth\n",
      "gelbart\n",
      "gutfreund\n",
      "shah\n",
      "torrijos\n",
      "bikers\n",
      "bofors\n",
      "parsow\n",
      "caci\n",
      "isi\n",
      "chestman\n",
      "tci\n",
      "trecker\n",
      "unilab\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-2442585950cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcatch_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "len(catch_unique(train.examples[0].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catch_unique(list_in):\n",
    "   # intilize an empty list\n",
    "   unq_list = []\n",
    "\n",
    "   # Check for elements\n",
    "   for x in list_in:\n",
    "      # check if exists in unq_list\n",
    "      if x not in unq_list:\n",
    "         unq_list.append(x)\n",
    "         # print list\n",
    "   return unq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}