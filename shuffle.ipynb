{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('transformer': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d0c581f552870128e643fa5d90873e1c0b3206e5e070517b42e73fec9b0f9803"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TextDataloader:\n",
    "    def __init__(self, dataset, max_seq_len, batch_size, shuffle=True):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # shuffle logic vars\n",
    "        self.shuffle = shuffle\n",
    "        self.chunk_len = max_seq_len * batch_size\n",
    "        \n",
    "        # trim dataset, fix for multigpu batching bugs\n",
    "        num_batches = math.ceil(len(dataset)/self.chunk_len)\n",
    "        trimmed_dataset_size = (num_batches - 1) * self.chunk_len + 1\n",
    "        self.dataset = dataset[0: trimmed_dataset_size]\n",
    "        self.dataset_len = trimmed_dataset_size\n",
    "\n",
    "        self.batch_order = np.array(range(num_batches))\n",
    "        \n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.batch_order)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index > len(self.batch_order) - 1:\n",
    "            raise StopIteration\n",
    "\n",
    "        i = self.batch_order[self.index]\n",
    "\n",
    "        chunk_pos = i * self.chunk_len\n",
    "\n",
    "        data = self.dataset[chunk_pos: chunk_pos + self.chunk_len]\n",
    "        target = self.dataset[(chunk_pos) + 1: (chunk_pos + self.chunk_len) + 1]\n",
    "\n",
    "        num_batches = min(self.batch_size, (self.dataset_len - chunk_pos) // self.max_seq_len)\n",
    "        if num_batches == 0:\n",
    "            raise StopIteration\n",
    "\n",
    "        if(len(data) != len(target)):\n",
    "            # remove mismatched batch sizes\n",
    "            data = data.narrow(0, 0, self.max_seq_len * (num_batches - 1))\n",
    "            target = target.narrow(0, 0, self.max_seq_len * (num_batches -1))\n",
    "\n",
    "        self.index += 1\n",
    "\n",
    "        return self.batchify(data, target, num_batches)\n",
    "\n",
    "    \n",
    "    def batchify(self, data, target, num_batches):\n",
    "        # Evenly divide the data across the batch_size batches.\n",
    "        data = data.view(num_batches, -1).contiguous()\n",
    "        target = target.view(num_batches, -1).contiguous()\n",
    "\n",
    "        # shuffle data\n",
    "        if self.shuffle:\n",
    "            permutation = torch.randperm(data.size(0))\n",
    "            data = data[permutation]\n",
    "            target = target[permutation]\n",
    "       \n",
    "        # flatten targets\n",
    "        target = target.reshape(-1)\n",
    "        return data, target.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data.shape - targets.shape:  torch.Size([5, 10]) torch.Size([50])\ndata.shape - targets.shape:  torch.Size([5, 10]) torch.Size([50])\ndata.shape - targets.shape:  torch.Size([5, 10]) torch.Size([50])\ndata.shape - targets.shape:  torch.Size([5, 10]) torch.Size([50])\ndata.shape - targets.shape:  torch.Size([5, 10]) torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "length = 300\n",
    "batch_size = 5\n",
    "max_seq_len = 10\n",
    "\n",
    "# chunk_len = max_seq_len * batch_size\n",
    "\n",
    "# num_chunks = math.ceil(length/ chunk_len)\n",
    "# print(num_chunks)\n",
    "# resized = (num_chunks - 1) * chunk_len + 1\n",
    "# print(resized)\n",
    "# print(resized//chunk_len)\n",
    "dataset = torch.arange(0, length)\n",
    "dataloader = TextDataloader(dataset, max_seq_len, batch_size, False)\n",
    "for batch in dataloader:\n",
    "    data, targets = batch\n",
    "    print(\"data.shape - targets.shape: \", data.shape,  targets.shape)\n",
    "\n",
    "    # print(data)\n",
    "    # print(targets)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Order: [3 4 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "length = 300\n",
    "batch_size = 5\n",
    "seq_len = 10\n",
    "chunk_len = seq_len * batch_size\n",
    "\n",
    "num_batches = math.ceil(length/chunk_len)\n",
    "num_batches\n",
    "# t = torch.rand(num_batches)\n",
    "# print('Original Tensor:', t)\n",
    "\n",
    "order = np.array(range(5))\n",
    "np.random.shuffle(order)\n",
    "print('Order:', order)\n",
    "# order[]\n",
    "\n",
    "# in-place changing of values\n",
    "data[np.array(range(5))] = data[order]\n",
    "# print('New Tensor:', t)\n",
    "\n",
    "# chunk_len = seq_len * batch_size\n",
    "# print(chunk_len)\n",
    "# data = torch.arange(0, length)\n",
    "# data = batchify(data, batch_size)\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]])"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "r=torch.randperm(data.size(0))\n",
    "d2 = data[r]\n",
    "d2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}