{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('transformer': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d0c581f552870128e643fa5d90873e1c0b3206e5e070517b42e73fec9b0f9803"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TextDataloader:\n",
    "    def __init__(self, dataset, max_seq_len, batch_size, shuffle=True):\n",
    "        self.dataset = dataset\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset_len = len(dataset)\n",
    "        \n",
    "        # shuffle logic\n",
    "        self.shuffle = shuffle\n",
    "        self.chunk_len = max_seq_len * batch_size\n",
    "        num_batches = math.ceil(self.dataset_len/self.chunk_len)\n",
    "        self.batch_order = np.array(range(num_batches))\n",
    "        \n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.batch_order)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index > len(self.batch_order) - 1:\n",
    "            raise StopIteration\n",
    "\n",
    "        i = self.batch_order[self.index]\n",
    "\n",
    "        chunk_pos = i * self.chunk_len\n",
    "\n",
    "        data = self.dataset[chunk_pos: chunk_pos + self.chunk_len]\n",
    "        target = self.dataset[(chunk_pos) + 1: (chunk_pos + self.chunk_len) + 1]\n",
    "\n",
    "        num_batches = min(self.batch_size, (self.dataset_len - chunk_pos) // self.max_seq_len)\n",
    "        if num_batches == 0:\n",
    "            raise StopIteration\n",
    "\n",
    "        if(len(data) != len(target)):\n",
    "            # remove mismatched batch sizes\n",
    "            data = data.narrow(0, 0, self.max_seq_len * (num_batches))\n",
    "            target = target.narrow(0, 0, self.max_seq_len * (num_batches))\n",
    "\n",
    "        self.index += 1\n",
    "\n",
    "        return self.batchify(data, target, num_batches)\n",
    "\n",
    "    \n",
    "    def batchify(self, data, target, num_batches):\n",
    "        # Evenly divide the data across the batch_size batches.\n",
    "        data = data.view(num_batches, -1).contiguous()\n",
    "        target = target.view(num_batches, -1).contiguous()\n",
    "\n",
    "        # shuffle data\n",
    "        if self.shuffle:\n",
    "            permutation = torch.randperm(data.size(0))\n",
    "            data = data[permutation]\n",
    "            target = target[permutation]\n",
    "       \n",
    "        # flatten targets\n",
    "        target = target.reshape(-1)\n",
    "        return data, target.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data/Target Shapes torch.Size([5, 10]) torch.Size([50])\ntensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]])\ntensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])\nData/Target Shapes torch.Size([5, 10]) torch.Size([50])\ntensor([[50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n        [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])\ntensor([ 51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n         93,  94,  95,  96,  97,  98,  99, 100])\nData/Target Shapes torch.Size([5, 10]) torch.Size([50])\ntensor([[100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n        [110, 111, 112, 113, 114, 115, 116, 117, 118, 119],\n        [120, 121, 122, 123, 124, 125, 126, 127, 128, 129],\n        [130, 131, 132, 133, 134, 135, 136, 137, 138, 139],\n        [140, 141, 142, 143, 144, 145, 146, 147, 148, 149]])\ntensor([101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n        115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n        129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n        143, 144, 145, 146, 147, 148, 149, 150])\nData/Target Shapes torch.Size([5, 10]) torch.Size([50])\ntensor([[150, 151, 152, 153, 154, 155, 156, 157, 158, 159],\n        [160, 161, 162, 163, 164, 165, 166, 167, 168, 169],\n        [170, 171, 172, 173, 174, 175, 176, 177, 178, 179],\n        [180, 181, 182, 183, 184, 185, 186, 187, 188, 189],\n        [190, 191, 192, 193, 194, 195, 196, 197, 198, 199]])\ntensor([151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n        165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178,\n        179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n        193, 194, 195, 196, 197, 198, 199, 200])\nData/Target Shapes torch.Size([5, 10]) torch.Size([50])\ntensor([[200, 201, 202, 203, 204, 205, 206, 207, 208, 209],\n        [210, 211, 212, 213, 214, 215, 216, 217, 218, 219],\n        [220, 221, 222, 223, 224, 225, 226, 227, 228, 229],\n        [230, 231, 232, 233, 234, 235, 236, 237, 238, 239],\n        [240, 241, 242, 243, 244, 245, 246, 247, 248, 249]])\ntensor([201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214,\n        215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n        229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242,\n        243, 244, 245, 246, 247, 248, 249, 250])\nData/Target Shapes torch.Size([5, 10]) torch.Size([50])\ntensor([[250, 251, 252, 253, 254, 255, 256, 257, 258, 259],\n        [260, 261, 262, 263, 264, 265, 266, 267, 268, 269],\n        [270, 271, 272, 273, 274, 275, 276, 277, 278, 279],\n        [280, 281, 282, 283, 284, 285, 286, 287, 288, 289],\n        [290, 291, 292, 293, 294, 295, 296, 297, 298, 299]])\ntensor([251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n        265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278,\n        279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292,\n        293, 294, 295, 296, 297, 298, 299, 300])\nData/Target Shapes torch.Size([3, 10]) torch.Size([30])\ntensor([[300, 301, 302, 303, 304, 305, 306, 307, 308, 309],\n        [310, 311, 312, 313, 314, 315, 316, 317, 318, 319],\n        [320, 321, 322, 323, 324, 325, 326, 327, 328, 329]])\ntensor([301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314,\n        315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328,\n        329, 330])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "length = 331\n",
    "batch_size = 5\n",
    "max_seq_len = 10\n",
    "\n",
    "dataset = torch.arange(0, length)\n",
    "dataloader = TextDataloader(dataset, max_seq_len, batch_size, False)\n",
    "for batch in dataloader:\n",
    "    data, targets = batch\n",
    "    print(\"Data/Target Shapes\", data.shape, targets.shape)\n",
    "    print(data)\n",
    "    print(targets)\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Order: [3 4 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "length = 300\n",
    "batch_size = 5\n",
    "seq_len = 10\n",
    "chunk_len = seq_len * batch_size\n",
    "\n",
    "num_batches = math.ceil(length/chunk_len)\n",
    "num_batches\n",
    "# t = torch.rand(num_batches)\n",
    "# print('Original Tensor:', t)\n",
    "\n",
    "order = np.array(range(5))\n",
    "np.random.shuffle(order)\n",
    "print('Order:', order)\n",
    "# order[]\n",
    "\n",
    "# in-place changing of values\n",
    "data[np.array(range(5))] = data[order]\n",
    "# print('New Tensor:', t)\n",
    "\n",
    "# chunk_len = seq_len * batch_size\n",
    "# print(chunk_len)\n",
    "# data = torch.arange(0, length)\n",
    "# data = batchify(data, batch_size)\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]])"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "r=torch.randperm(data.size(0))\n",
    "d2 = data[r]\n",
    "d2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}