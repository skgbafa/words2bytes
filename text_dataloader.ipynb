{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('transformer': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d0c581f552870128e643fa5d90873e1c0b3206e5e070517b42e73fec9b0f9803"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class TextDataloader:\n",
    "    def __init__(self, dataset, max_seq_len, batch_size, shuffle=True):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # shuffle logic vars\n",
    "        self.shuffle = shuffle\n",
    "        self.chunk_len = max_seq_len * batch_size\n",
    "\n",
    "        # get seqence order\n",
    "        num_seqs = (len(dataset) - 1) // self.max_seq_len\n",
    "        self.seq_order = np.array(range(num_seqs))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.seq_order)\n",
    "\n",
    "        # get source, target datasets, trim\n",
    "        self.dataset = dataset\n",
    "        self.source = self.shuffle_dataset(dataset[0: len(dataset) - 1])\n",
    "        self.targets = self.shuffle_dataset(dataset[1: len(dataset)])\n",
    "        \n",
    "        # fill remaining batch with beginning\n",
    "        epoch_fill_count = (batch_size - num_seqs % batch_size ) * self.max_seq_len\n",
    "        self.source = torch.cat([self.source, self.source[0:epoch_fill_count]])\n",
    "        self.targets = torch.cat([self.targets, self.targets[0:epoch_fill_count]])\n",
    "        \n",
    "        self.dataset_len = len(self.source)\n",
    "        self.num_batches = ((self.dataset_len - 1) // self.max_seq_len) // self.batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        i = self.index\n",
    "        chunk_pos = i * self.chunk_len\n",
    "        data = self.source[chunk_pos: chunk_pos + self.chunk_len]\n",
    "        target = self.targets[chunk_pos: chunk_pos + self.chunk_len]\n",
    "        num_batches = min(self.batch_size, (self.dataset_len - chunk_pos) // self.max_seq_len)\n",
    " \n",
    "        if num_batches == 0:\n",
    "            raise StopIteration\n",
    "\n",
    "        self.index += 1\n",
    "        return self.batchify(data, target, num_batches)\n",
    "\n",
    "    def batchify(self, data, target, num_batches):\n",
    "        # Evenly divide the data across the batch_size batches.\n",
    "        data = data.view(num_batches, -1).contiguous()\n",
    "        target = target.view(num_batches, -1).contiguous()\n",
    "\n",
    "        # shuffle data\n",
    "        if self.shuffle:\n",
    "            permutation = torch.randperm(data.size(0))\n",
    "            data = data[permutation]\n",
    "            target = target[permutation]\n",
    "\n",
    "        # flatten targets\n",
    "        target = target.reshape(-1)\n",
    "        return data, target.reshape(-1)\n",
    "\n",
    "    def shuffle_dataset(self, dataset):\n",
    "        shuffled_dataset = map(\n",
    "            lambda x: dataset[x * self.max_seq_len: (x + 1) * self.max_seq_len], self.seq_order)\n",
    "        return torch.cat(list(shuffled_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69],\n        [ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59],\n        [100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n        [ 80,  81,  82,  83,  84,  85,  86,  87,  88,  89],\n        [110, 111, 112, 113, 114, 115, 116, 117, 118, 119]])\ntensor([[30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99],\n        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])\ntensor([[110, 111, 112, 113, 114, 115, 116, 117, 118, 119],\n        [ 20,  21,  22,  23,  24,  25,  26,  27,  28,  29],\n        [100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n        [ 80,  81,  82,  83,  84,  85,  86,  87,  88,  89],\n        [ 40,  41,  42,  43,  44,  45,  46,  47,  48,  49]])\n"
     ]
    }
   ],
   "source": [
    "# test TextDataloader\n",
    "import torch\n",
    "\n",
    "length = 121\n",
    "batch_size = 5\n",
    "max_seq_len = 10\n",
    "\n",
    "\n",
    "dataset = torch.arange(0, length)\n",
    "dataloader = TextDataloader(dataset, max_seq_len, batch_size, True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    data, targets = batch\n",
    "    print(data)\n",
    "    # print(targets)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12\n[ 4  3  6  0  7  2  9 11  5  1 10  8]\n30\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "length = 122\n",
    "batch_size = 5\n",
    "max_seq_len = 10\n",
    "\n",
    "# num_seqs = math.ceil((length - 1) / max_seq_len)\n",
    "# num_seqs = (length - 1 ) // max_seq_len\n",
    "print(num_seqs)\n",
    "seq_order = np.array(range(num_seqs))\n",
    "\n",
    "np.random.shuffle(seq_order)\n",
    "print(seq_order)\n",
    "\n",
    "# dataset = torch.arange(0, length)\n",
    "# shuffled_dataset = map(lambda x: dataset[x * max_seq_len: (x + 1)* max_seq_len], seq_order)\n",
    "# print(torch.cat(list(shuffled_dataset)))\n",
    "\n",
    "# def shuffle_dataset(dataset):\n",
    "#     shuffled_dataset = map(lambda x: dataset[x * max_seq_len: (x + 1)* max_seq_len], seq_order)\n",
    "#     return torch.cat(list(shuffled_dataset))\n",
    "\n",
    "data = dataset[0: len(dataset) - 1]\n",
    "targets = dataset[1: len(dataset)]\n",
    "# print(shuffle_dataset(data))\n",
    "# print(shuffle_dataset(targets))\n",
    "\n",
    "\n",
    "epoch_fill_count = (batch_size - num_seqs % batch_size ) * max_seq_len\n",
    "print(epoch_fill_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "torch.cat([torch.tensor([], torch.tensor([0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}