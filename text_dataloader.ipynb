{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('transformer': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d0c581f552870128e643fa5d90873e1c0b3206e5e070517b42e73fec9b0f9803"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class TextDataloader:\n",
    "    def __init__(self, dataset, max_seq_len, batch_size, shuffle=True):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # shuffle logic vars\n",
    "        self.shuffle = shuffle\n",
    "        self.chunk_len = max_seq_len * batch_size\n",
    "\n",
    "        # get seqence order\n",
    "        num_seqs = (length - 1) // max_seq_len\n",
    "        self.seq_order = np.array(range(num_seqs))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.seq_order)\n",
    "\n",
    "        # get source, target datasets, trim\n",
    "        self.dataset = dataset\n",
    "        self.source = self.shuffle_dataset(dataset[0: len(dataset) - 1])\n",
    "        self.targets = self.shuffle_dataset(dataset[1: len(dataset)])\n",
    "        self.dataset_len = len(self.source)\n",
    "        self.num_batches = math.ceil(num_seqs/self.batch_size)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index > self.num_batches - 1:\n",
    "            raise StopIteration\n",
    "\n",
    "        i = self.index\n",
    "        chunk_pos = i * self.chunk_len\n",
    "        data = self.source[chunk_pos: chunk_pos + self.chunk_len]\n",
    "        target = self.targets[chunk_pos: chunk_pos + self.chunk_len]\n",
    " \n",
    "        num_batches = min(self.batch_size, (self.dataset_len - chunk_pos) // self.max_seq_len)\n",
    "        if num_batches == 0:\n",
    "            raise StopIteration\n",
    "\n",
    "        if(len(data) != len(target)):\n",
    "            # remove mismatched batch sizes\n",
    "            data = data.narrow(0, 0, self.max_seq_len * (num_batches - 1))\n",
    "            target = target.narrow(0, 0, self.max_seq_len * (num_batches - 1))\n",
    "\n",
    "        self.index += 1\n",
    "\n",
    "        return self.batchify(data, target, num_batches)\n",
    "\n",
    "    def batchify(self, data, target, num_batches):\n",
    "        # Evenly divide the data across the batch_size batches.\n",
    "        data = data.view(num_batches, -1).contiguous()\n",
    "        target = target.view(num_batches, -1).contiguous()\n",
    "\n",
    "        # shuffle data\n",
    "        if self.shuffle:\n",
    "            permutation = torch.randperm(data.size(0))\n",
    "            data = data[permutation]\n",
    "            target = target[permutation]\n",
    "\n",
    "        # flatten targets\n",
    "        target = target.reshape(-1)\n",
    "        return data, target.reshape(-1)\n",
    "\n",
    "    def shuffle_dataset(self, dataset):\n",
    "        shuffled_dataset = map(lambda x: dataset[x * max_seq_len: (x + 1)* max_seq_len], self.seq_order)\n",
    "        return torch.cat(list(shuffled_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[ 80,  81,  82,  83,  84,  85,  86,  87,  88,  89],\n        [120, 121, 122, 123, 124, 125, 126, 127, 128, 129],\n        [ 40,  41,  42,  43,  44,  45,  46,  47,  48,  49],\n        [ 70,  71,  72,  73,  74,  75,  76,  77,  78,  79],\n        [ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39]])\ntensor([ 81,  82,  83,  84,  85,  86,  87,  88,  89,  90, 121, 122, 123, 124,\n        125, 126, 127, 128, 129, 130,  41,  42,  43,  44,  45,  46,  47,  48,\n         49,  50,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  31,  32,\n         33,  34,  35,  36,  37,  38,  39,  40])\ntensor([[ 20,  21,  22,  23,  24,  25,  26,  27,  28,  29],\n        [130, 131, 132, 133, 134, 135, 136, 137, 138, 139],\n        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9],\n        [110, 111, 112, 113, 114, 115, 116, 117, 118, 119],\n        [ 10,  11,  12,  13,  14,  15,  16,  17,  18,  19]])\ntensor([ 21,  22,  23,  24,  25,  26,  27,  28,  29,  30, 131, 132, 133, 134,\n        135, 136, 137, 138, 139, 140,   1,   2,   3,   4,   5,   6,   7,   8,\n          9,  10, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,  11,  12,\n         13,  14,  15,  16,  17,  18,  19,  20])\ntensor([[100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n        [ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59],\n        [ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69],\n        [ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99]])\ntensor([101, 102, 103, 104, 105, 106, 107, 108, 109, 110,  51,  52,  53,  54,\n         55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,\n         69,  70,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100])\n"
     ]
    }
   ],
   "source": [
    "# test TextDataloader\n",
    "import torch\n",
    "\n",
    "length = 149\n",
    "batch_size = 5\n",
    "max_seq_len = 10\n",
    "\n",
    "\n",
    "dataset = torch.arange(0, length)\n",
    "dataloader = TextDataloader(dataset, max_seq_len, batch_size, True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    data, targets = batch\n",
    "    print(data)\n",
    "    print(targets)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[6 1 2 0 8 7 5 4 3]\ntensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 10, 11, 12, 13, 14, 15, 16, 17,\n        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,  0,  1,  2,  3,  4,  5,\n         6,  7,  8,  9, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 70, 71, 72, 73,\n        74, 75, 76, 77, 78, 79, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 40, 41,\n        42, 43, 44, 45, 46, 47, 48, 49, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39])\ntensor([60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 10, 11, 12, 13, 14, 15, 16, 17,\n        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,  0,  1,  2,  3,  4,  5,\n         6,  7,  8,  9, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 70, 71, 72, 73,\n        74, 75, 76, 77, 78, 79, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 40, 41,\n        42, 43, 44, 45, 46, 47, 48, 49, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39])\ntensor([61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 11, 12, 13, 14, 15, 16, 17, 18,\n        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,  1,  2,  3,  4,  5,  6,\n         7,  8,  9, 10, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 71, 72, 73, 74,\n        75, 76, 77, 78, 79, 80, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 41, 42,\n        43, 44, 45, 46, 47, 48, 49, 50, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "length = 100\n",
    "batch_size = 5\n",
    "max_seq_len = 10\n",
    "\n",
    "# num_seqs = math.ceil((length - 1) / max_seq_len)\n",
    "num_seqs = (length - 1 ) // max_seq_len\n",
    "# print(num_seqs)\n",
    "seq_order = np.array(range(num_seqs))\n",
    "\n",
    "np.random.shuffle(seq_order)\n",
    "print(seq_order)\n",
    "\n",
    "dataset = torch.arange(0, length)\n",
    "shuffled_dataset = map(lambda x: dataset[x * max_seq_len: (x + 1)* max_seq_len], seq_order)\n",
    "print(torch.cat(list(shuffled_dataset)))\n",
    "\n",
    "def shuffle_dataset(dataset):\n",
    "    shuffled_dataset = map(lambda x: dataset[x * max_seq_len: (x + 1)* max_seq_len], seq_order)\n",
    "    return torch.cat(list(shuffled_dataset))\n",
    "\n",
    "data = dataset[0: len(dataset) - 1]\n",
    "targets = dataset[1: len(dataset)]\n",
    "print(shuffle_dataset(data))\n",
    "print(shuffle_dataset(targets))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}