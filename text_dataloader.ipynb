{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('transformer': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d0c581f552870128e643fa5d90873e1c0b3206e5e070517b42e73fec9b0f9803"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class TextDataloader:\n",
    "    previous_source = torch.tensor([])\n",
    "    previous_target = torch.tensor([])\n",
    "\n",
    "    def __init__(self, dataset, max_seq_len, batch_size, shuffle=True, include_previous=True):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # shuffle logic vars\n",
    "        self.shuffle = shuffle\n",
    "        self.chunk_len = max_seq_len * batch_size\n",
    "\n",
    "        # get seqence order\n",
    "        num_seqs = (len(dataset) - 1) // max_seq_len\n",
    "        self.seq_order = np.array(range(num_seqs))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.seq_order)\n",
    "\n",
    "        # get source, target datasets, trim\n",
    "        self.dataset = dataset\n",
    "        self.source = self.shuffle_dataset(dataset[0: len(dataset) - 1])\n",
    "        self.targets = self.shuffle_dataset(dataset[1: len(dataset)])\n",
    "        self.num_batches = num_seqs // self.batch_size # trim off non-conforming batches\n",
    "\n",
    "        if include_previous: # leftover data from previous run is included\n",
    "            self.source = torch.cat([TextDataloader.previous_source, self.source])\n",
    "            self.target = torch.cat([TextDataloader.previous_target, self.targets])\n",
    "            self.num_batches = math.ceil(num_seqs/self.batch_size) # include non-conforming batches\n",
    "        \n",
    "        self.dataset_len = len(self.source)\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index > self.num_batches - 1:\n",
    "            raise StopIteration\n",
    "\n",
    "        i = self.index\n",
    "        chunk_pos = i * self.chunk_len\n",
    "        data = self.source[chunk_pos: chunk_pos + self.chunk_len]\n",
    "        target = self.targets[chunk_pos: chunk_pos + self.chunk_len]\n",
    " \n",
    "        num_batches = min(self.batch_size, (self.dataset_len - chunk_pos) // self.max_seq_len)\n",
    "        if num_batches < self.batch_size:\n",
    "            TextDataloader.previous_source = data\n",
    "            TextDataloader.previous_target = target\n",
    "            \n",
    "        # if num_batches == 0:\n",
    "            raise StopIteration\n",
    "\n",
    "        self.index += 1\n",
    "        print(self.batch_size)\n",
    "        return self.batchify(data, target, num_batches)\n",
    "\n",
    "    def batchify(self, data, target, num_batches):\n",
    "        # Evenly divide the data across the batch_size batches.\n",
    "        data = data.view(num_batches, -1).contiguous()\n",
    "        target = target.view(num_batches, -1).contiguous()\n",
    "\n",
    "        # shuffle data\n",
    "        if self.shuffle:\n",
    "            permutation = torch.randperm(data.size(0))\n",
    "            data = data[permutation]\n",
    "            target = target[permutation]\n",
    "\n",
    "        # flatten targets\n",
    "        target = target.reshape(-1)\n",
    "        return data, target.reshape(-1)\n",
    "\n",
    "    def shuffle_dataset(self, dataset):\n",
    "        shuffled_dataset = map(lambda x: dataset[x * self.max_seq_len: (x + 1)* self.max_seq_len], self.seq_order)\n",
    "        return torch.cat(list(shuffled_dataset))\n",
    "\n",
    "    def reset_previous():\n",
    "        TextDataloader.previous_source = torch.tensor([])\n",
    "        TextDataloader.previous_target = torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "TextDataloader.reset_previous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5\ntensor([[100., 101., 102., 103., 104., 105., 106., 107., 108., 109.],\n        [  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.],\n        [ 10.,  11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.],\n        [ 20.,  21.,  22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.],\n        [ 30.,  31.,  32.,  33.,  34.,  35.,  36.,  37.,  38.,  39.]])\ntensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n        19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n        37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50])\n5\ntensor([[40., 41., 42., 43., 44., 45., 46., 47., 48., 49.],\n        [50., 51., 52., 53., 54., 55., 56., 57., 58., 59.],\n        [60., 61., 62., 63., 64., 65., 66., 67., 68., 69.],\n        [70., 71., 72., 73., 74., 75., 76., 77., 78., 79.],\n        [80., 81., 82., 83., 84., 85., 86., 87., 88., 89.]])\ntensor([ 51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,\n         93,  94,  95,  96,  97,  98,  99, 100])\n"
     ]
    }
   ],
   "source": [
    "# test TextDataloader\n",
    "import torch\n",
    "\n",
    "length = 111\n",
    "batch_size = 5\n",
    "max_seq_len = 10\n",
    "\n",
    "\n",
    "dataset = torch.arange(0, length)\n",
    "dataloader = TextDataloader(dataset, max_seq_len, batch_size, False)\n",
    "\n",
    "for batch in dataloader:\n",
    "    data, targets = batch\n",
    "    print(data)\n",
    "    print(targets)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 5  2 11  6  3  1  4  9 10  8  0  7]\ntensor([ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  20,  21,  22,  23,\n         24,  25,  26,  27,  28,  29, 110, 111, 112, 113, 114, 115, 116, 117,\n        118, 119,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  30,  31,\n         32,  33,  34,  35,  36,  37,  38,  39,  10,  11,  12,  13,  14,  15,\n         16,  17,  18,  19,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,\n         90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n        104, 105, 106, 107, 108, 109,  80,  81,  82,  83,  84,  85,  86,  87,\n         88,  89,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  70,  71,\n         72,  73,  74,  75,  76,  77,  78,  79])\ntensor([ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  20,  21,  22,  23,\n         24,  25,  26,  27,  28,  29, 110, 111, 112, 113, 114, 115, 116, 117,\n        118, 119,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  30,  31,\n         32,  33,  34,  35,  36,  37,  38,  39,  10,  11,  12,  13,  14,  15,\n         16,  17,  18,  19,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,\n         90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n        104, 105, 106, 107, 108, 109,  80,  81,  82,  83,  84,  85,  86,  87,\n         88,  89,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  70,  71,\n         72,  73,  74,  75,  76,  77,  78,  79])\ntensor([ 51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  21,  22,  23,  24,\n         25,  26,  27,  28,  29,  30, 111, 112, 113, 114, 115, 116, 117, 118,\n        119, 120,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  31,  32,\n         33,  34,  35,  36,  37,  38,  39,  40,  11,  12,  13,  14,  15,  16,\n         17,  18,  19,  20,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,\n         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n        105, 106, 107, 108, 109, 110,  81,  82,  83,  84,  85,  86,  87,  88,\n         89,  90,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  71,  72,\n         73,  74,  75,  76,  77,  78,  79,  80])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "length = 122\n",
    "batch_size = 5\n",
    "max_seq_len = 10\n",
    "\n",
    "# num_seqs = math.ceil((length - 1) / max_seq_len)\n",
    "num_seqs = (length - 1 ) // max_seq_len\n",
    "# print(num_seqs)\n",
    "seq_order = np.array(range(num_seqs))\n",
    "\n",
    "np.random.shuffle(seq_order)\n",
    "print(seq_order)\n",
    "\n",
    "dataset = torch.arange(0, length)\n",
    "shuffled_dataset = map(lambda x: dataset[x * max_seq_len: (x + 1)* max_seq_len], seq_order)\n",
    "print(torch.cat(list(shuffled_dataset)))\n",
    "\n",
    "def shuffle_dataset(dataset):\n",
    "    shuffled_dataset = map(lambda x: dataset[x * max_seq_len: (x + 1)* max_seq_len], seq_order)\n",
    "    return torch.cat(list(shuffled_dataset))\n",
    "\n",
    "data = dataset[0: len(dataset) - 1]\n",
    "targets = dataset[1: len(dataset)]\n",
    "print(shuffle_dataset(data))\n",
    "print(shuffle_dataset(targets))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "torch.cat([torch.tensor([], torch.tensor([0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}