{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('transformer': conda)",
   "metadata": {
    "interpreter": {
     "hash": "d0c581f552870128e643fa5d90873e1c0b3206e5e070517b42e73fec9b0f9803"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "class TextDataloader:\n",
    "    def __init__(self, dataset, max_seq_len, batch_size, shuffle=True):\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # shuffle logic vars\n",
    "        self.shuffle = shuffle\n",
    "        self.chunk_len = max_seq_len * batch_size\n",
    "\n",
    "        # get seqence order\n",
    "        num_seqs = (length - 1) // max_seq_len\n",
    "        self.seq_order = np.array(range(num_seqs))\n",
    "        if shuffle:\n",
    "            np.random.shuffle(self.seq_order)\n",
    "\n",
    "        # get source, target datasets, trim\n",
    "        self.dataset = dataset\n",
    "        self.source = self.shuffle_dataset(dataset[0: len(dataset) - 1])\n",
    "        self.targets = self.shuffle_dataset(dataset[1: len(dataset)])\n",
    "        self.dataset_len = len(self.source)\n",
    "        # self.num_batches = math.ceil(num_seqs/self.batch_size) # include non-conforming batches\n",
    "        self.num_batches = num_seqs // self.batch_size # trim off non-conforming batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.index = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.index > self.num_batches - 1:\n",
    "            raise StopIteration\n",
    "\n",
    "        i = self.index\n",
    "        chunk_pos = i * self.chunk_len\n",
    "        data = self.source[chunk_pos: chunk_pos + self.chunk_len]\n",
    "        target = self.targets[chunk_pos: chunk_pos + self.chunk_len]\n",
    " \n",
    "        num_batches = min(self.batch_size, (self.dataset_len - chunk_pos) // self.max_seq_len)\n",
    "        if num_batches == 0:\n",
    "            raise StopIteration\n",
    "\n",
    "        if(len(data) != len(target)):\n",
    "            # remove mismatched batch sizes\n",
    "            data = data.narrow(0, 0, self.max_seq_len * (num_batches - 1))\n",
    "            target = target.narrow(0, 0, self.max_seq_len * (num_batches - 1))\n",
    "\n",
    "        self.index += 1\n",
    "\n",
    "        return self.batchify(data, target, num_batches)\n",
    "\n",
    "    def batchify(self, data, target, num_batches):\n",
    "        # Evenly divide the data across the batch_size batches.\n",
    "        data = data.view(num_batches, -1).contiguous()\n",
    "        target = target.view(num_batches, -1).contiguous()\n",
    "\n",
    "        # shuffle data\n",
    "        if self.shuffle:\n",
    "            permutation = torch.randperm(data.size(0))\n",
    "            data = data[permutation]\n",
    "            target = target[permutation]\n",
    "\n",
    "        # flatten targets\n",
    "        target = target.reshape(-1)\n",
    "        return data, target.reshape(-1)\n",
    "\n",
    "    def shuffle_dataset(self, dataset):\n",
    "        shuffled_dataset = map(lambda x: dataset[x * max_seq_len: (x + 1)* max_seq_len], self.seq_order)\n",
    "        return torch.cat(list(shuffled_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n        [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9],\n        [ 10,  11,  12,  13,  14,  15,  16,  17,  18,  19],\n        [ 90,  91,  92,  93,  94,  95,  96,  97,  98,  99],\n        [130, 131, 132, 133, 134, 135, 136, 137, 138, 139]])\ntensor([101, 102, 103, 104, 105, 106, 107, 108, 109, 110,   1,   2,   3,   4,\n          5,   6,   7,   8,   9,  10,  11,  12,  13,  14,  15,  16,  17,  18,\n         19,  20,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 131, 132,\n        133, 134, 135, 136, 137, 138, 139, 140])\ntensor([[ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69],\n        [ 40,  41,  42,  43,  44,  45,  46,  47,  48,  49],\n        [ 20,  21,  22,  23,  24,  25,  26,  27,  28,  29],\n        [ 70,  71,  72,  73,  74,  75,  76,  77,  78,  79],\n        [110, 111, 112, 113, 114, 115, 116, 117, 118, 119]])\ntensor([ 61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  41,  42,  43,  44,\n         45,  46,  47,  48,  49,  50,  21,  22,  23,  24,  25,  26,  27,  28,\n         29,  30,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80, 111, 112,\n        113, 114, 115, 116, 117, 118, 119, 120])\n"
     ]
    }
   ],
   "source": [
    "# test TextDataloader\n",
    "import torch\n",
    "\n",
    "length = 149\n",
    "batch_size = 5\n",
    "max_seq_len = 10\n",
    "\n",
    "\n",
    "dataset = torch.arange(0, length)\n",
    "dataloader = TextDataloader(dataset, max_seq_len, batch_size, True)\n",
    "\n",
    "for batch in dataloader:\n",
    "    data, targets = batch\n",
    "    print(data)\n",
    "    print(targets)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-937668cd8430>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnum_seqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# print(num_seqs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mseq_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "length = 122\n",
    "batch_size = 5\n",
    "max_seq_len = 10\n",
    "\n",
    "# num_seqs = math.ceil((length - 1) / max_seq_len)\n",
    "num_seqs = (length - 1 ) // max_seq_len\n",
    "# print(num_seqs)\n",
    "seq_order = np.array(range(num_seqs))\n",
    "\n",
    "np.random.shuffle(seq_order)\n",
    "print(seq_order)\n",
    "\n",
    "dataset = torch.arange(0, length)\n",
    "shuffled_dataset = map(lambda x: dataset[x * max_seq_len: (x + 1)* max_seq_len], seq_order)\n",
    "print(torch.cat(list(shuffled_dataset)))\n",
    "\n",
    "def shuffle_dataset(dataset):\n",
    "    shuffled_dataset = map(lambda x: dataset[x * max_seq_len: (x + 1)* max_seq_len], seq_order)\n",
    "    return torch.cat(list(shuffled_dataset))\n",
    "\n",
    "data = dataset[0: len(dataset) - 1]\n",
    "targets = dataset[1: len(dataset)]\n",
    "print(shuffle_dataset(data))\n",
    "print(shuffle_dataset(targets))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}